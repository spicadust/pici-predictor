{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal: train 10 machine learning predictors: one predictor for each function from the ten protein function categories (\"DNA, RNA and nucleotide metabolism\", \"tail\", \"head and packaging\", \"other\", \"lysis\", \"connector\", \"transcription regulation\", \"moron, auxiliary metabolic gene and host takeover\", \"unknown function\", \"integration and excision\") \n",
    "\n",
    "predictor input: protein features; output: labels (0/1) representing whether the protein serves the specific function\n",
    "\n",
    "dataset: 360,413 seqs in total - 60% for training, 20% for validation, 20% for testing \n",
    "** subset the negatives (samples whose label is 0) and make it about 5-10 times of the positives\n",
    "** change: split 20% for testing first, then train:val = 8:2\n",
    "\n",
    "-use clustering results to avoid spliting protein seqs in the same cluster (maybe use GroupShuffleSplit from sklearn)\n",
    "** change: for each predictor, cluster on the positive dataset (those with label \"1\") alone, and do nothing to negative dataset. use the clustering result while splitting dataset to ensure seqs in the same cluster in positive dataset is not splitted into different sets of train/val/test. I already have protein distances generated from diamond blastp in unique_diamond_results.daa, and would like to get the clustering result by select a cutoff of 100bitscore and use that to read into a graph with networkx and then extract subgraphs which then will be the clusters.\n",
    "\n",
    "** change: add learning curve for training XGBoost\n",
    "\n",
    "** change: try the 100 versions of threshold from 0.01 - 1\n",
    "\n",
    "the results are printed as text.  \n",
    "** change: not to print them out but to save it to results/predictor/{function_name}.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset:  \n",
    "2,318,538 seqs in the original dataset  \n",
    "927,040 seqs after dropping pcat \"unknown_no_hit\"  \n",
    "360,413 unique seqs after dropping duplicated seqs  \n",
    "\n",
    "features: 1711-dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset the negatives;  \n",
    "- for each function, cluster on the positive dataset  \n",
    "- try threshold from 0.01 to 1  \n",
    "- [o] change the dataset splitting strategy  \n",
    "- [o] model param : is_imbalanced  \n",
    "- add learning curve (could be find from XGBoost)  \n",
    "- n_estimators: increased to 10k; may need GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, Dict, Any\n",
    "import joblib\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(function_name: str):\n",
    "    ids = pd.read_csv(f\"../dataset/pcat/{function_name}.csv\")\n",
    "    features = pd.read_parquet(\"../dataset/protein_features_unique.pa\")\n",
    "    features[\"label\"] = features[\"id\"].isin(ids[\"name\"]).astype(int)\n",
    "    features = features.drop(columns=[\"md5\"])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_negatives(\n",
    "    df: pd.DataFrame, label_col: str = \"label\", ratio: int = 5, random_state: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Subset the negatives to be `ratio` times the number of positives.\n",
    "    Args:\n",
    "        df: DataFrame with a label column\n",
    "        label_col: Name of the label column\n",
    "        ratio: Negative:positive ratio\n",
    "        random_state: For reproducibility\n",
    "    Returns:\n",
    "        Subsetted DataFrame\n",
    "    \"\"\"\n",
    "    pos_df = df[df[label_col] == 1]\n",
    "    neg_df = df[df[label_col] == 0]\n",
    "    n_pos = len(pos_df)\n",
    "    n_neg = min(len(neg_df), n_pos * ratio)\n",
    "    neg_df = neg_df.sample(n=n_neg, random_state=random_state)\n",
    "    return (\n",
    "        pd.concat([pos_df, neg_df])\n",
    "        .sample(frac=1, random_state=random_state)\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_positives(\n",
    "    df, bitscore_file, bitscore_cutoff=100, id_col=\"id\", label_col=\"label\"\n",
    "):\n",
    "    pos_ids = set(df[df[label_col] == 1][id_col])\n",
    "\n",
    "    # Load diamond results (parquet)\n",
    "    diamond = pd.read_parquet(bitscore_file)\n",
    "    # If needed, rename columns here:\n",
    "    # diamond = diamond.rename(columns={\"col1\": \"qseqid\", \"col2\": \"sseqid\", \"col3\": \"bitscore\"})\n",
    "\n",
    "    # Filter for bitscore cutoff and only positive IDs\n",
    "    diamond = diamond[\n",
    "        (diamond[\"bitscore\"] >= bitscore_cutoff)\n",
    "        & (diamond[\"qseqid\"].isin(pos_ids))\n",
    "        & (diamond[\"sseqid\"].isin(pos_ids))\n",
    "    ]\n",
    "\n",
    "    # Build graph\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(diamond[[\"qseqid\", \"sseqid\"]].itertuples(index=False, name=None))\n",
    "\n",
    "    # Assign cluster IDs\n",
    "    cluster_mapping = {}\n",
    "    for i, component in enumerate(nx.connected_components(G)):\n",
    "        for node in component:\n",
    "            cluster_mapping[node] = f\"cluster_{i}\"\n",
    "\n",
    "    # Assign unconnected positives to their own cluster\n",
    "    for pid in pos_ids:\n",
    "        if pid not in cluster_mapping:\n",
    "            cluster_mapping[pid] = f\"cluster_single_{pid}\"\n",
    "\n",
    "    return cluster_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: list,\n",
    "    cluster_mapping: Dict[str, str],\n",
    "    label_col: str = \"label\",\n",
    "    id_col: str = \"id\",\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Prepare data for training by separating features and labels.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing features and labels\n",
    "        feature_cols: List of feature column names\n",
    "        cluster_mapping: Dictionary mapping sequence IDs to cluster IDs\n",
    "        label_col: Name of the label column\n",
    "        id_col: Name of the ID column\n",
    "\n",
    "    Returns:\n",
    "        X: Feature matrix\n",
    "        y: Label array\n",
    "        ids: Array of sequence IDs\n",
    "        groups: Array of cluster IDs for each sequence\n",
    "    \"\"\"\n",
    "    X = df[feature_cols].values\n",
    "    y = df[label_col].values\n",
    "    ids = df[id_col].values\n",
    "\n",
    "    # Get cluster IDs for each sequence\n",
    "    groups = np.array([cluster_mapping.get(str(id_), \"unknown\") for id_ in ids])\n",
    "\n",
    "    return X, y, ids, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    ids: np.ndarray,\n",
    "    groups: np.ndarray,\n",
    "    test_size: float = 0.2,\n",
    "    val_size: float = 0.2,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Split data into train, validation, and test sets while keeping related sequences together.\n",
    "\n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Label array\n",
    "        ids: Array of sequence IDs\n",
    "        groups: Array of cluster IDs for each sequence\n",
    "        test_size: Proportion of data to use for testing\n",
    "        val_size: Proportion of data to use for validation\n",
    "    \"\"\"\n",
    "    # First split: separate test set\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    train_val_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val = groups[train_val_idx]\n",
    "\n",
    "    # Second split: separate validation set from training set\n",
    "    val_size_adjusted = val_size / (\n",
    "        1 - test_size\n",
    "    )  # Adjust val_size to account for test set\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=val_size_adjusted, random_state=42)\n",
    "    train_idx, val_idx = next(\n",
    "        gss.split(X_train_val, y_train_val, groups=groups_train_val)\n",
    "    )\n",
    "\n",
    "    X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "    y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# first split: test 20%\n",
    "# train:val = 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_val: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    model_params: Dict[str, Any] = None,\n",
    ") -> Tuple[Any, StandardScaler]:\n",
    "    \"\"\"Train an XGBoost classifier with optional hyperparameters.\"\"\"\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Set default parameters if none provided\n",
    "    if model_params is None:\n",
    "        model_params = {\n",
    "            \"n_estimators\": 200,\n",
    "            \"max_depth\": 6,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"min_child_weight\": 1,\n",
    "            \"scale_pos_weight\": 1,\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "\n",
    "    # Calculate scale_pos_weight based on class imbalance\n",
    "    n_neg = np.sum(y_train == 0)\n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    model_params[\"scale_pos_weight\"] = n_neg / n_pos\n",
    "\n",
    "    # Train model\n",
    "    model = XGBClassifier(eval_metric=[\"logloss\", \"auc\"], **model_params)\n",
    "    model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        eval_set=[(X_train_scaled, y_train), (X_val_scaled, y_val)],\n",
    "        verbose=False,\n",
    "        # early_stopping_rounds=50,\n",
    "    )\n",
    "    evals_result = model.evals_result()\n",
    "    return model, scaler, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: Any,\n",
    "    scaler: StandardScaler,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    set_name: str = \"\",\n",
    "    threshold: float = 0.5,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance on a dataset.\"\"\"\n",
    "\n",
    "    # no need for scaling!\n",
    "\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y_pred_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate MCC\n",
    "    def matthews(y_true, y_pred):\n",
    "        from math import sqrt\n",
    "\n",
    "        \"\"\"\n",
    "            P  = Total number of positives\n",
    "            N  = Total number of negatives\n",
    "            Tp = number of true positives\n",
    "            Fp = number of false positives\n",
    "        \"\"\"\n",
    "        if type(y_true) == pd.Series:\n",
    "            y_true = y_true.values\n",
    "\n",
    "        P = len([x for x in y_true if x == 1])\n",
    "        N = len([x for x in y_true if x == 0])\n",
    "\n",
    "        Tp, Fp = 0, 0\n",
    "        for i in range(len(y_true)):\n",
    "            if y_true[i] == 1 and y_pred[i] == 1:\n",
    "                Tp += 1\n",
    "            elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "                Fp += 1\n",
    "\n",
    "        Tn = N - Fp\n",
    "        Fn = P - Tp\n",
    "\n",
    "        try:\n",
    "            mcc = (Tp * Tn - Fp * Fn) / sqrt(\n",
    "                (Tn + Fn) * (Tn + Fp) * (Tp + Fn) * (Tp + Fp)\n",
    "            )\n",
    "        except ZeroDivisionError:\n",
    "            mcc = 0\n",
    "        return (mcc, f\"P: {P:_} Tp: {Tp:_} Fp: {Fp:_} N: {N:_} Tn: {Tn:_} Fn: {Fn:_}\")\n",
    "\n",
    "    # Get MCC and confusion matrix values\n",
    "    mcc, confusion_str = matthews(y, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        f\"{set_name}_accuracy\": accuracy_score(y, y_pred),\n",
    "        f\"{set_name}_precision\": precision_score(y, y_pred),\n",
    "        f\"{set_name}_recall\": recall_score(y, y_pred),\n",
    "        f\"{set_name}_f1\": f1_score(y, y_pred),\n",
    "        f\"{set_name}_roc_auc\": roc_auc_score(y, y_pred_proba),\n",
    "        f\"{set_name}_mcc\": mcc,\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\nMetrics for {set_name} (threshold={threshold}):\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Print confusion matrix values\n",
    "    print(f\"\\nConfusion Matrix Values:\")\n",
    "    print(confusion_str)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_feature_importance(model: Any, feature_cols: list, top_n: int = 20):\n",
    "#     \"\"\"Plot feature importance from XGBoost model.\"\"\"\n",
    "#     importance_scores = model.feature_importances_\n",
    "#     indices = np.argsort(importance_scores)[::-1]\n",
    "\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.title(\"Feature Importances\")\n",
    "#     plt.bar(range(top_n), importance_scores[indices[:top_n]])\n",
    "#     plt.xticks(range(top_n), [feature_cols[i] for i in indices[:top_n]], rotation=90)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # Print top N most important features\n",
    "#     print(f\"\\nTop {top_n} most important features:\")\n",
    "#     for i in range(top_n):\n",
    "#         print(f\"{feature_cols[indices[i]]}: {importance_scores[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(\n",
    "    model: Any, scaler: StandardScaler, feature_cols: list, function_name: str\n",
    "):\n",
    "    \"\"\"Save the trained model and scaler.\"\"\"\n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "    # Create a dictionary containing all necessary components\n",
    "    model_data = {\"model\": model, \"scaler\": scaler, \"feature_cols\": feature_cols}\n",
    "\n",
    "    # Save the model data\n",
    "    joblib.dump(model_data, f\"../models/{function_name}_predictor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function_predictor(function_name: str, model_params: Dict[str, Any] = None):\n",
    "    \"\"\"Main training pipeline for a specific protein function.\"\"\"\n",
    "    # # Load cluster mapping\n",
    "    # with open(\"../dataset/protein_cluster_mapping.json\", \"r\") as f:\n",
    "    #     cluster_mapping = json.load(f)\n",
    "\n",
    "    # get df using function name\n",
    "    df = get_df(function_name)\n",
    "    df = subset_negatives(df, ratio=5)\n",
    "\n",
    "    # Cluster positives using diamond results\n",
    "    bitscore_file = \"../dataset/unique_diamond_results.parquet\"\n",
    "    cluster_mapping = cluster_positives(df, bitscore_file, bitscore_cutoff=100)\n",
    "\n",
    "    # Assign dummy group to negatives\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"label\"] == 0:\n",
    "            cluster_mapping[row[\"id\"]] = f\"neg_{row['id']}\"\n",
    "\n",
    "    # Get feature columns (excluding 'id' and 'label')\n",
    "    feature_cols = [col for col in df.columns if col not in [\"id\", \"label\"]]\n",
    "\n",
    "    # Prepare data\n",
    "    X, y, ids, groups = prepare_data(df, feature_cols, cluster_mapping)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, ids, groups)\n",
    "\n",
    "    # Train model\n",
    "    model, scaler, evals_result = train_model(\n",
    "        X_train, y_train, X_val, y_val, model_params\n",
    "    )\n",
    "\n",
    "    train_metric = evals_result[\"validation_0\"][\"logloss\"]\n",
    "    val_metric = evals_result[\"validation_1\"][\"logloss\"]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_metric, label=\"Train Logloss\")\n",
    "    plt.plot(val_metric, label=\"Val Logloss\")\n",
    "    plt.xlabel(\"Boosting Round\")\n",
    "    plt.ylabel(\"Logloss\")\n",
    "    plt.title(f\"Learning Curve: {function_name}\")\n",
    "    plt.legend()\n",
    "    os.makedirs(f\"../results/predictor\", exist_ok=True)\n",
    "    plt.savefig(f\"../results/predictor/{function_name}_learning_curve.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Collect results in a list of strings\n",
    "    results_lines = []\n",
    "\n",
    "    # Feature importances\n",
    "    importance_scores = model.feature_importances_\n",
    "    indices = np.argsort(importance_scores)[::-1]\n",
    "    results_lines.append(\"Top 20 most important features:\")\n",
    "    for i in range(20):\n",
    "        results_lines.append(\n",
    "            f\"{feature_cols[indices[i]]}: {importance_scores[indices[i]]:.4f}\"\n",
    "        )\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Train metrics\n",
    "    train_metrics = evaluate_model(model, scaler, X_train, y_train, \"train\")\n",
    "    results_lines.append(\"=== Training Set ===\")\n",
    "    for k, v in train_metrics.items():\n",
    "        results_lines.append(f\"{k}: {v}\")\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Validation metrics\n",
    "    val_metrics = evaluate_model(model, scaler, X_val, y_val, \"val\")\n",
    "    results_lines.append(\"=== Validation Set ===\")\n",
    "    for k, v in val_metrics.items():\n",
    "        results_lines.append(f\"{k}: {v}\")\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Test metrics for all thresholds\n",
    "    results_lines.append(\"=== Test Set ===\")\n",
    "    thresholds = np.linspace(0.01, 1.0, 100)\n",
    "    best_mcc = -float(\"inf\")\n",
    "    best_threshold = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        test_metrics = evaluate_model(model, scaler, X_test, y_test, \"test\", threshold)\n",
    "        results_lines.append(f\"Threshold: {threshold:.2f}\")\n",
    "        for k, v in test_metrics.items():\n",
    "            results_lines.append(f\"{k}: {v}\")\n",
    "        results_lines.append(\"\")\n",
    "        # Track best MCC\n",
    "        mcc = test_metrics.get(\"test_mcc\", -float(\"inf\"))\n",
    "        if isinstance(\n",
    "            mcc, tuple\n",
    "        ):  # If your evaluate_model returns (mcc, confusion_str)\n",
    "            mcc = mcc[0]\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    # Add the best MCC summary line\n",
    "    results_lines.append(f\"Best MCC: {best_mcc:.4f} at threshold {best_threshold:.2f}\")\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Save all results to file\n",
    "    os.makedirs(\"../results/predictor\", exist_ok=True)\n",
    "    result_file = f\"../results/predictor/{function_name}.txt\"\n",
    "    with open(result_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(results_lines))\n",
    "\n",
    "    # Save model\n",
    "    save_model(model, scaler, feature_cols, function_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for testing early stopping\n",
    "# import xgboost\n",
    "\n",
    "# print(\"XGBoost version:\", xgboost.__version__)\n",
    "\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X, y = load_iris(return_X_y=True)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# model = XGBClassifier(n_estimators=10)\n",
    "# model.fit(\n",
    "#     X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5, verbose=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for train (threshold=0.5):\n",
      "train_accuracy: 0.9995\n",
      "train_precision: 0.9968\n",
      "train_recall: 1.0000\n",
      "train_f1: 0.9984\n",
      "train_roc_auc: 1.0000\n",
      "train_mcc: 0.9981\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 9_166 Tp: 9_166 Fp: 29 N: 47_865 Tn: 47_836 Fn: 0\n",
      "\n",
      "Metrics for val (threshold=0.5):\n",
      "val_accuracy: 0.8679\n",
      "val_precision: 0.9115\n",
      "val_recall: 0.3141\n",
      "val_f1: 0.4672\n",
      "val_roc_auc: 0.8476\n",
      "val_mcc: 0.4884\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_607 Tp: 1_133 Fp: 110 N: 15_948 Tn: 15_838 Fn: 2_474\n",
      "\n",
      "Metrics for test (threshold=0.01):\n",
      "test_accuracy: 0.3480\n",
      "test_precision: 0.1992\n",
      "test_recall: 0.9677\n",
      "test_f1: 0.3304\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.1814\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 3_082 Fp: 12_390 N: 15_977 Tn: 3_587 Fn: 103\n",
      "\n",
      "Metrics for test (threshold=0.02):\n",
      "test_accuracy: 0.5314\n",
      "test_precision: 0.2498\n",
      "test_recall: 0.9083\n",
      "test_f1: 0.3918\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2775\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 2_893 Fp: 8_688 N: 15_977 Tn: 7_289 Fn: 292\n",
      "\n",
      "Metrics for test (threshold=0.03):\n",
      "test_accuracy: 0.6295\n",
      "test_precision: 0.2858\n",
      "test_recall: 0.8198\n",
      "test_f1: 0.4238\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3066\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 2_611 Fp: 6_526 N: 15_977 Tn: 9_451 Fn: 574\n",
      "\n",
      "Metrics for test (threshold=0.04):\n",
      "test_accuracy: 0.6918\n",
      "test_precision: 0.3185\n",
      "test_recall: 0.7495\n",
      "test_f1: 0.4470\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3279\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 2_387 Fp: 5_107 N: 15_977 Tn: 10_870 Fn: 798\n",
      "\n",
      "Metrics for test (threshold=0.05):\n",
      "test_accuracy: 0.7348\n",
      "test_precision: 0.3515\n",
      "test_recall: 0.7042\n",
      "test_f1: 0.4689\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3516\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 2_243 Fp: 4_139 N: 15_977 Tn: 11_838 Fn: 942\n",
      "\n",
      "Metrics for test (threshold=0.060000000000000005):\n",
      "test_accuracy: 0.7641\n",
      "test_precision: 0.3792\n",
      "test_recall: 0.6581\n",
      "test_f1: 0.4811\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3642\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 2_096 Fp: 3_432 N: 15_977 Tn: 12_545 Fn: 1_089\n",
      "\n",
      "Metrics for test (threshold=0.06999999999999999):\n",
      "test_accuracy: 0.7874\n",
      "test_precision: 0.4099\n",
      "test_recall: 0.6345\n",
      "test_f1: 0.4980\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3852\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 2_021 Fp: 2_910 N: 15_977 Tn: 13_067 Fn: 1_164\n",
      "\n",
      "Metrics for test (threshold=0.08):\n",
      "test_accuracy: 0.8050\n",
      "test_precision: 0.4382\n",
      "test_recall: 0.6129\n",
      "test_f1: 0.5110\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4021\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_952 Fp: 2_503 N: 15_977 Tn: 13_474 Fn: 1_233\n",
      "\n",
      "Metrics for test (threshold=0.09):\n",
      "test_accuracy: 0.8188\n",
      "test_precision: 0.4646\n",
      "test_recall: 0.5906\n",
      "test_f1: 0.5200\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4148\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_881 Fp: 2_168 N: 15_977 Tn: 13_809 Fn: 1_304\n",
      "\n",
      "Metrics for test (threshold=0.09999999999999999):\n",
      "test_accuracy: 0.8298\n",
      "test_precision: 0.4898\n",
      "test_recall: 0.5724\n",
      "test_f1: 0.5279\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4268\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_823 Fp: 1_899 N: 15_977 Tn: 14_078 Fn: 1_362\n",
      "\n",
      "Metrics for test (threshold=0.11):\n",
      "test_accuracy: 0.8368\n",
      "test_precision: 0.5084\n",
      "test_recall: 0.5510\n",
      "test_f1: 0.5289\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4309\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_755 Fp: 1_697 N: 15_977 Tn: 14_280 Fn: 1_430\n",
      "\n",
      "Metrics for test (threshold=0.12):\n",
      "test_accuracy: 0.8443\n",
      "test_precision: 0.5315\n",
      "test_recall: 0.5322\n",
      "test_f1: 0.5318\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4385\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_695 Fp: 1_494 N: 15_977 Tn: 14_483 Fn: 1_490\n",
      "\n",
      "Metrics for test (threshold=0.13):\n",
      "test_accuracy: 0.8497\n",
      "test_precision: 0.5513\n",
      "test_recall: 0.5143\n",
      "test_f1: 0.5322\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4431\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_638 Fp: 1_333 N: 15_977 Tn: 14_644 Fn: 1_547\n",
      "\n",
      "Metrics for test (threshold=0.14):\n",
      "test_accuracy: 0.8549\n",
      "test_precision: 0.5726\n",
      "test_recall: 0.5005\n",
      "test_f1: 0.5341\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4500\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_594 Fp: 1_190 N: 15_977 Tn: 14_787 Fn: 1_591\n",
      "\n",
      "Metrics for test (threshold=0.15000000000000002):\n",
      "test_accuracy: 0.8578\n",
      "test_precision: 0.5883\n",
      "test_recall: 0.4823\n",
      "test_f1: 0.5300\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4503\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_536 Fp: 1_075 N: 15_977 Tn: 14_902 Fn: 1_649\n",
      "\n",
      "Metrics for test (threshold=0.16):\n",
      "test_accuracy: 0.8617\n",
      "test_precision: 0.6088\n",
      "test_recall: 0.4700\n",
      "test_f1: 0.5305\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4561\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_497 Fp: 962 N: 15_977 Tn: 15_015 Fn: 1_688\n",
      "\n",
      "Metrics for test (threshold=0.17):\n",
      "test_accuracy: 0.8638\n",
      "test_precision: 0.6230\n",
      "test_recall: 0.4581\n",
      "test_f1: 0.5280\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4578\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_459 Fp: 883 N: 15_977 Tn: 15_094 Fn: 1_726\n",
      "\n",
      "Metrics for test (threshold=0.18000000000000002):\n",
      "test_accuracy: 0.8659\n",
      "test_precision: 0.6389\n",
      "test_recall: 0.4449\n",
      "test_f1: 0.5245\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4594\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_417 Fp: 801 N: 15_977 Tn: 15_176 Fn: 1_768\n",
      "\n",
      "Metrics for test (threshold=0.19):\n",
      "test_accuracy: 0.8670\n",
      "test_precision: 0.6497\n",
      "test_recall: 0.4339\n",
      "test_f1: 0.5203\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4590\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_382 Fp: 745 N: 15_977 Tn: 15_232 Fn: 1_803\n",
      "\n",
      "Metrics for test (threshold=0.2):\n",
      "test_accuracy: 0.8689\n",
      "test_precision: 0.6654\n",
      "test_recall: 0.4245\n",
      "test_f1: 0.5183\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4618\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_352 Fp: 680 N: 15_977 Tn: 15_297 Fn: 1_833\n",
      "\n",
      "Metrics for test (threshold=0.21000000000000002):\n",
      "test_accuracy: 0.8700\n",
      "test_precision: 0.6779\n",
      "test_recall: 0.4151\n",
      "test_f1: 0.5149\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4627\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_322 Fp: 628 N: 15_977 Tn: 15_349 Fn: 1_863\n",
      "\n",
      "Metrics for test (threshold=0.22):\n",
      "test_accuracy: 0.8712\n",
      "test_precision: 0.6916\n",
      "test_recall: 0.4057\n",
      "test_f1: 0.5114\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4639\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_292 Fp: 576 N: 15_977 Tn: 15_401 Fn: 1_893\n",
      "\n",
      "Metrics for test (threshold=0.23):\n",
      "test_accuracy: 0.8715\n",
      "test_precision: 0.6990\n",
      "test_recall: 0.3981\n",
      "test_f1: 0.5073\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4628\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_268 Fp: 546 N: 15_977 Tn: 15_431 Fn: 1_917\n",
      "\n",
      "Metrics for test (threshold=0.24000000000000002):\n",
      "test_accuracy: 0.8703\n",
      "test_precision: 0.7005\n",
      "test_recall: 0.3840\n",
      "test_f1: 0.4960\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4544\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_223 Fp: 523 N: 15_977 Tn: 15_454 Fn: 1_962\n",
      "\n",
      "Metrics for test (threshold=0.25):\n",
      "test_accuracy: 0.8705\n",
      "test_precision: 0.7084\n",
      "test_recall: 0.3752\n",
      "test_f1: 0.4906\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4525\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_195 Fp: 492 N: 15_977 Tn: 15_485 Fn: 1_990\n",
      "\n",
      "Metrics for test (threshold=0.26):\n",
      "test_accuracy: 0.8708\n",
      "test_precision: 0.7171\n",
      "test_recall: 0.3677\n",
      "test_f1: 0.4861\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4517\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_171 Fp: 462 N: 15_977 Tn: 15_515 Fn: 2_014\n",
      "\n",
      "Metrics for test (threshold=0.27):\n",
      "test_accuracy: 0.8714\n",
      "test_precision: 0.7277\n",
      "test_recall: 0.3617\n",
      "test_f1: 0.4832\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4526\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_152 Fp: 431 N: 15_977 Tn: 15_546 Fn: 2_033\n",
      "\n",
      "Metrics for test (threshold=0.28):\n",
      "test_accuracy: 0.8711\n",
      "test_precision: 0.7360\n",
      "test_recall: 0.3501\n",
      "test_f1: 0.4745\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4484\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_115 Fp: 400 N: 15_977 Tn: 15_577 Fn: 2_070\n",
      "\n",
      "Metrics for test (threshold=0.29000000000000004):\n",
      "test_accuracy: 0.8707\n",
      "test_precision: 0.7411\n",
      "test_recall: 0.3416\n",
      "test_f1: 0.4677\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4448\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_088 Fp: 380 N: 15_977 Tn: 15_597 Fn: 2_097\n",
      "\n",
      "Metrics for test (threshold=0.3):\n",
      "test_accuracy: 0.8709\n",
      "test_precision: 0.7509\n",
      "test_recall: 0.3341\n",
      "test_f1: 0.4624\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4438\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_064 Fp: 353 N: 15_977 Tn: 15_624 Fn: 2_121\n",
      "\n",
      "Metrics for test (threshold=0.31):\n",
      "test_accuracy: 0.8709\n",
      "test_precision: 0.7612\n",
      "test_recall: 0.3253\n",
      "test_f1: 0.4558\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4419\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_036 Fp: 325 N: 15_977 Tn: 15_652 Fn: 2_149\n",
      "\n",
      "Metrics for test (threshold=0.32):\n",
      "test_accuracy: 0.8702\n",
      "test_precision: 0.7646\n",
      "test_recall: 0.3162\n",
      "test_f1: 0.4474\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4367\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 1_007 Fp: 310 N: 15_977 Tn: 15_667 Fn: 2_178\n",
      "\n",
      "Metrics for test (threshold=0.33):\n",
      "test_accuracy: 0.8700\n",
      "test_precision: 0.7726\n",
      "test_recall: 0.3083\n",
      "test_f1: 0.4408\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4342\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 982 Fp: 289 N: 15_977 Tn: 15_688 Fn: 2_203\n",
      "\n",
      "Metrics for test (threshold=0.34):\n",
      "test_accuracy: 0.8701\n",
      "test_precision: 0.7818\n",
      "test_recall: 0.3027\n",
      "test_f1: 0.4364\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4337\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 964 Fp: 269 N: 15_977 Tn: 15_708 Fn: 2_221\n",
      "\n",
      "Metrics for test (threshold=0.35000000000000003):\n",
      "test_accuracy: 0.8696\n",
      "test_precision: 0.7868\n",
      "test_recall: 0.2954\n",
      "test_f1: 0.4296\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4301\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 941 Fp: 255 N: 15_977 Tn: 15_722 Fn: 2_244\n",
      "\n",
      "Metrics for test (threshold=0.36000000000000004):\n",
      "test_accuracy: 0.8696\n",
      "test_precision: 0.7937\n",
      "test_recall: 0.2911\n",
      "test_f1: 0.4259\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4294\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 927 Fp: 241 N: 15_977 Tn: 15_736 Fn: 2_258\n",
      "\n",
      "Metrics for test (threshold=0.37):\n",
      "test_accuracy: 0.8701\n",
      "test_precision: 0.8030\n",
      "test_recall: 0.2892\n",
      "test_f1: 0.4252\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4316\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 921 Fp: 226 N: 15_977 Tn: 15_751 Fn: 2_264\n",
      "\n",
      "Metrics for test (threshold=0.38):\n",
      "test_accuracy: 0.8703\n",
      "test_precision: 0.8114\n",
      "test_recall: 0.2863\n",
      "test_f1: 0.4233\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4326\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 912 Fp: 212 N: 15_977 Tn: 15_765 Fn: 2_273\n",
      "\n",
      "Metrics for test (threshold=0.39):\n",
      "test_accuracy: 0.8700\n",
      "test_precision: 0.8166\n",
      "test_recall: 0.2810\n",
      "test_f1: 0.4181\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4303\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 895 Fp: 201 N: 15_977 Tn: 15_776 Fn: 2_290\n",
      "\n",
      "Metrics for test (threshold=0.4):\n",
      "test_accuracy: 0.8698\n",
      "test_precision: 0.8220\n",
      "test_recall: 0.2769\n",
      "test_f1: 0.4143\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4290\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 882 Fp: 191 N: 15_977 Tn: 15_786 Fn: 2_303\n",
      "\n",
      "Metrics for test (threshold=0.41000000000000003):\n",
      "test_accuracy: 0.8700\n",
      "test_precision: 0.8305\n",
      "test_recall: 0.2738\n",
      "test_f1: 0.4118\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4296\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 872 Fp: 178 N: 15_977 Tn: 15_799 Fn: 2_313\n",
      "\n",
      "Metrics for test (threshold=0.42000000000000004):\n",
      "test_accuracy: 0.8701\n",
      "test_precision: 0.8417\n",
      "test_recall: 0.2688\n",
      "test_f1: 0.4074\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4296\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 856 Fp: 161 N: 15_977 Tn: 15_816 Fn: 2_329\n",
      "\n",
      "Metrics for test (threshold=0.43):\n",
      "test_accuracy: 0.8696\n",
      "test_precision: 0.8438\n",
      "test_recall: 0.2647\n",
      "test_f1: 0.4030\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4269\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 843 Fp: 156 N: 15_977 Tn: 15_821 Fn: 2_342\n",
      "\n",
      "Metrics for test (threshold=0.44):\n",
      "test_accuracy: 0.8695\n",
      "test_precision: 0.8498\n",
      "test_recall: 0.2612\n",
      "test_f1: 0.3996\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4261\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 832 Fp: 147 N: 15_977 Tn: 15_830 Fn: 2_353\n",
      "\n",
      "Metrics for test (threshold=0.45):\n",
      "test_accuracy: 0.8694\n",
      "test_precision: 0.8559\n",
      "test_recall: 0.2575\n",
      "test_f1: 0.3958\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4250\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 820 Fp: 138 N: 15_977 Tn: 15_839 Fn: 2_365\n",
      "\n",
      "Metrics for test (threshold=0.46):\n",
      "test_accuracy: 0.8691\n",
      "test_precision: 0.8627\n",
      "test_recall: 0.2524\n",
      "test_f1: 0.3906\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4230\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 804 Fp: 128 N: 15_977 Tn: 15_849 Fn: 2_381\n",
      "\n",
      "Metrics for test (threshold=0.47000000000000003):\n",
      "test_accuracy: 0.8680\n",
      "test_precision: 0.8636\n",
      "test_recall: 0.2446\n",
      "test_f1: 0.3812\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4164\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 779 Fp: 123 N: 15_977 Tn: 15_854 Fn: 2_406\n",
      "\n",
      "Metrics for test (threshold=0.48000000000000004):\n",
      "test_accuracy: 0.8677\n",
      "test_precision: 0.8692\n",
      "test_recall: 0.2399\n",
      "test_f1: 0.3760\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4140\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 764 Fp: 115 N: 15_977 Tn: 15_862 Fn: 2_421\n",
      "\n",
      "Metrics for test (threshold=0.49):\n",
      "test_accuracy: 0.8666\n",
      "test_precision: 0.8678\n",
      "test_recall: 0.2330\n",
      "test_f1: 0.3673\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4073\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 742 Fp: 113 N: 15_977 Tn: 15_864 Fn: 2_443\n",
      "\n",
      "Metrics for test (threshold=0.5):\n",
      "test_accuracy: 0.8656\n",
      "test_precision: 0.8692\n",
      "test_recall: 0.2254\n",
      "test_f1: 0.3580\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.4008\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 718 Fp: 108 N: 15_977 Tn: 15_869 Fn: 2_467\n",
      "\n",
      "Metrics for test (threshold=0.51):\n",
      "test_accuracy: 0.8652\n",
      "test_precision: 0.8707\n",
      "test_recall: 0.2220\n",
      "test_f1: 0.3538\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3981\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 707 Fp: 105 N: 15_977 Tn: 15_872 Fn: 2_478\n",
      "\n",
      "Metrics for test (threshold=0.52):\n",
      "test_accuracy: 0.8648\n",
      "test_precision: 0.8761\n",
      "test_recall: 0.2176\n",
      "test_f1: 0.3486\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3957\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 693 Fp: 98 N: 15_977 Tn: 15_879 Fn: 2_492\n",
      "\n",
      "Metrics for test (threshold=0.53):\n",
      "test_accuracy: 0.8644\n",
      "test_precision: 0.8766\n",
      "test_recall: 0.2141\n",
      "test_f1: 0.3442\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3926\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 682 Fp: 96 N: 15_977 Tn: 15_881 Fn: 2_503\n",
      "\n",
      "Metrics for test (threshold=0.54):\n",
      "test_accuracy: 0.8633\n",
      "test_precision: 0.8772\n",
      "test_recall: 0.2063\n",
      "test_f1: 0.3340\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3852\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 657 Fp: 92 N: 15_977 Tn: 15_885 Fn: 2_528\n",
      "\n",
      "Metrics for test (threshold=0.55):\n",
      "test_accuracy: 0.8630\n",
      "test_precision: 0.8836\n",
      "test_recall: 0.2025\n",
      "test_f1: 0.3295\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3835\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 645 Fp: 85 N: 15_977 Tn: 15_892 Fn: 2_540\n",
      "\n",
      "Metrics for test (threshold=0.56):\n",
      "test_accuracy: 0.8623\n",
      "test_precision: 0.8878\n",
      "test_recall: 0.1962\n",
      "test_f1: 0.3214\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3785\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 625 Fp: 79 N: 15_977 Tn: 15_898 Fn: 2_560\n",
      "\n",
      "Metrics for test (threshold=0.5700000000000001):\n",
      "test_accuracy: 0.8621\n",
      "test_precision: 0.8918\n",
      "test_recall: 0.1940\n",
      "test_f1: 0.3187\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3775\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 618 Fp: 75 N: 15_977 Tn: 15_902 Fn: 2_567\n",
      "\n",
      "Metrics for test (threshold=0.5800000000000001):\n",
      "test_accuracy: 0.8618\n",
      "test_precision: 0.8943\n",
      "test_recall: 0.1912\n",
      "test_f1: 0.3151\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3754\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 609 Fp: 72 N: 15_977 Tn: 15_905 Fn: 2_576\n",
      "\n",
      "Metrics for test (threshold=0.59):\n",
      "test_accuracy: 0.8614\n",
      "test_precision: 0.8979\n",
      "test_recall: 0.1878\n",
      "test_f1: 0.3106\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3730\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 598 Fp: 68 N: 15_977 Tn: 15_909 Fn: 2_587\n",
      "\n",
      "Metrics for test (threshold=0.6):\n",
      "test_accuracy: 0.8611\n",
      "test_precision: 0.8992\n",
      "test_recall: 0.1849\n",
      "test_f1: 0.3068\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3704\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 589 Fp: 66 N: 15_977 Tn: 15_911 Fn: 2_596\n",
      "\n",
      "Metrics for test (threshold=0.61):\n",
      "test_accuracy: 0.8605\n",
      "test_precision: 0.9013\n",
      "test_recall: 0.1805\n",
      "test_f1: 0.3008\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3664\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 575 Fp: 63 N: 15_977 Tn: 15_914 Fn: 2_610\n",
      "\n",
      "Metrics for test (threshold=0.62):\n",
      "test_accuracy: 0.8606\n",
      "test_precision: 0.9065\n",
      "test_recall: 0.1796\n",
      "test_f1: 0.2998\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3669\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 572 Fp: 59 N: 15_977 Tn: 15_918 Fn: 2_613\n",
      "\n",
      "Metrics for test (threshold=0.63):\n",
      "test_accuracy: 0.8600\n",
      "test_precision: 0.9088\n",
      "test_recall: 0.1752\n",
      "test_f1: 0.2938\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3629\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 558 Fp: 56 N: 15_977 Tn: 15_921 Fn: 2_627\n",
      "\n",
      "Metrics for test (threshold=0.64):\n",
      "test_accuracy: 0.8591\n",
      "test_precision: 0.9105\n",
      "test_recall: 0.1692\n",
      "test_f1: 0.2854\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3570\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 539 Fp: 53 N: 15_977 Tn: 15_924 Fn: 2_646\n",
      "\n",
      "Metrics for test (threshold=0.65):\n",
      "test_accuracy: 0.8588\n",
      "test_precision: 0.9108\n",
      "test_recall: 0.1667\n",
      "test_f1: 0.2818\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3543\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 531 Fp: 52 N: 15_977 Tn: 15_925 Fn: 2_654\n",
      "\n",
      "Metrics for test (threshold=0.66):\n",
      "test_accuracy: 0.8585\n",
      "test_precision: 0.9158\n",
      "test_recall: 0.1639\n",
      "test_f1: 0.2780\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3526\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 522 Fp: 48 N: 15_977 Tn: 15_929 Fn: 2_663\n",
      "\n",
      "Metrics for test (threshold=0.67):\n",
      "test_accuracy: 0.8582\n",
      "test_precision: 0.9179\n",
      "test_recall: 0.1614\n",
      "test_f1: 0.2745\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3503\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 514 Fp: 46 N: 15_977 Tn: 15_931 Fn: 2_671\n",
      "\n",
      "Metrics for test (threshold=0.68):\n",
      "test_accuracy: 0.8577\n",
      "test_precision: 0.9180\n",
      "test_recall: 0.1582\n",
      "test_f1: 0.2700\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3468\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 504 Fp: 45 N: 15_977 Tn: 15_932 Fn: 2_681\n",
      "\n",
      "Metrics for test (threshold=0.6900000000000001):\n",
      "test_accuracy: 0.8572\n",
      "test_precision: 0.9196\n",
      "test_recall: 0.1545\n",
      "test_f1: 0.2645\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3430\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 492 Fp: 43 N: 15_977 Tn: 15_934 Fn: 2_693\n",
      "\n",
      "Metrics for test (threshold=0.7000000000000001):\n",
      "test_accuracy: 0.8570\n",
      "test_precision: 0.9221\n",
      "test_recall: 0.1523\n",
      "test_f1: 0.2614\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3411\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 485 Fp: 41 N: 15_977 Tn: 15_936 Fn: 2_700\n",
      "\n",
      "Metrics for test (threshold=0.7100000000000001):\n",
      "test_accuracy: 0.8563\n",
      "test_precision: 0.9202\n",
      "test_recall: 0.1485\n",
      "test_f1: 0.2557\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3363\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 473 Fp: 41 N: 15_977 Tn: 15_936 Fn: 2_712\n",
      "\n",
      "Metrics for test (threshold=0.72):\n",
      "test_accuracy: 0.8561\n",
      "test_precision: 0.9263\n",
      "test_recall: 0.1460\n",
      "test_f1: 0.2522\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3349\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 465 Fp: 37 N: 15_977 Tn: 15_940 Fn: 2_720\n",
      "\n",
      "Metrics for test (threshold=0.73):\n",
      "test_accuracy: 0.8558\n",
      "test_precision: 0.9289\n",
      "test_recall: 0.1435\n",
      "test_f1: 0.2486\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3326\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 457 Fp: 35 N: 15_977 Tn: 15_942 Fn: 2_728\n",
      "\n",
      "Metrics for test (threshold=0.74):\n",
      "test_accuracy: 0.8554\n",
      "test_precision: 0.9314\n",
      "test_recall: 0.1407\n",
      "test_f1: 0.2444\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3298\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 448 Fp: 33 N: 15_977 Tn: 15_944 Fn: 2_737\n",
      "\n",
      "Metrics for test (threshold=0.75):\n",
      "test_accuracy: 0.8550\n",
      "test_precision: 0.9358\n",
      "test_recall: 0.1372\n",
      "test_f1: 0.2393\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3267\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 437 Fp: 30 N: 15_977 Tn: 15_947 Fn: 2_748\n",
      "\n",
      "Metrics for test (threshold=0.76):\n",
      "test_accuracy: 0.8545\n",
      "test_precision: 0.9342\n",
      "test_recall: 0.1338\n",
      "test_f1: 0.2340\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3221\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 426 Fp: 30 N: 15_977 Tn: 15_947 Fn: 2_759\n",
      "\n",
      "Metrics for test (threshold=0.77):\n",
      "test_accuracy: 0.8539\n",
      "test_precision: 0.9327\n",
      "test_recall: 0.1306\n",
      "test_f1: 0.2291\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3179\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 416 Fp: 30 N: 15_977 Tn: 15_947 Fn: 2_769\n",
      "\n",
      "Metrics for test (threshold=0.78):\n",
      "test_accuracy: 0.8534\n",
      "test_precision: 0.9332\n",
      "test_recall: 0.1272\n",
      "test_f1: 0.2238\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3136\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 405 Fp: 29 N: 15_977 Tn: 15_948 Fn: 2_780\n",
      "\n",
      "Metrics for test (threshold=0.79):\n",
      "test_accuracy: 0.8529\n",
      "test_precision: 0.9318\n",
      "test_recall: 0.1243\n",
      "test_f1: 0.2194\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3097\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 396 Fp: 29 N: 15_977 Tn: 15_948 Fn: 2_789\n",
      "\n",
      "Metrics for test (threshold=0.8):\n",
      "test_accuracy: 0.8527\n",
      "test_precision: 0.9393\n",
      "test_recall: 0.1215\n",
      "test_f1: 0.2152\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3078\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 387 Fp: 25 N: 15_977 Tn: 15_952 Fn: 2_798\n",
      "\n",
      "Metrics for test (threshold=0.81):\n",
      "test_accuracy: 0.8523\n",
      "test_precision: 0.9403\n",
      "test_recall: 0.1187\n",
      "test_f1: 0.2108\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3044\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 378 Fp: 24 N: 15_977 Tn: 15_953 Fn: 2_807\n",
      "\n",
      "Metrics for test (threshold=0.8200000000000001):\n",
      "test_accuracy: 0.8519\n",
      "test_precision: 0.9415\n",
      "test_recall: 0.1162\n",
      "test_f1: 0.2068\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.3013\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 370 Fp: 23 N: 15_977 Tn: 15_954 Fn: 2_815\n",
      "\n",
      "Metrics for test (threshold=0.8300000000000001):\n",
      "test_accuracy: 0.8513\n",
      "test_precision: 0.9398\n",
      "test_recall: 0.1127\n",
      "test_f1: 0.2013\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2964\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 359 Fp: 23 N: 15_977 Tn: 15_954 Fn: 2_826\n",
      "\n",
      "Metrics for test (threshold=0.8400000000000001):\n",
      "test_accuracy: 0.8510\n",
      "test_precision: 0.9435\n",
      "test_recall: 0.1102\n",
      "test_f1: 0.1974\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2938\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 351 Fp: 21 N: 15_977 Tn: 15_956 Fn: 2_834\n",
      "\n",
      "Metrics for test (threshold=0.85):\n",
      "test_accuracy: 0.8506\n",
      "test_precision: 0.9522\n",
      "test_recall: 0.1064\n",
      "test_f1: 0.1915\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2905\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 339 Fp: 17 N: 15_977 Tn: 15_960 Fn: 2_846\n",
      "\n",
      "Metrics for test (threshold=0.86):\n",
      "test_accuracy: 0.8495\n",
      "test_precision: 0.9494\n",
      "test_recall: 0.1002\n",
      "test_f1: 0.1812\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2811\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 319 Fp: 17 N: 15_977 Tn: 15_960 Fn: 2_866\n",
      "\n",
      "Metrics for test (threshold=0.87):\n",
      "test_accuracy: 0.8491\n",
      "test_precision: 0.9565\n",
      "test_recall: 0.0967\n",
      "test_f1: 0.1756\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2775\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 308 Fp: 14 N: 15_977 Tn: 15_963 Fn: 2_877\n",
      "\n",
      "Metrics for test (threshold=0.88):\n",
      "test_accuracy: 0.8480\n",
      "test_precision: 0.9533\n",
      "test_recall: 0.0898\n",
      "test_f1: 0.1641\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2667\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 286 Fp: 14 N: 15_977 Tn: 15_963 Fn: 2_899\n",
      "\n",
      "Metrics for test (threshold=0.89):\n",
      "test_accuracy: 0.8474\n",
      "test_precision: 0.9516\n",
      "test_recall: 0.0863\n",
      "test_f1: 0.1583\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2611\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 275 Fp: 14 N: 15_977 Tn: 15_963 Fn: 2_910\n",
      "\n",
      "Metrics for test (threshold=0.9):\n",
      "test_accuracy: 0.8465\n",
      "test_precision: 0.9485\n",
      "test_recall: 0.0810\n",
      "test_f1: 0.1493\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2522\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 258 Fp: 14 N: 15_977 Tn: 15_963 Fn: 2_927\n",
      "\n",
      "Metrics for test (threshold=0.91):\n",
      "test_accuracy: 0.8458\n",
      "test_precision: 0.9565\n",
      "test_recall: 0.0760\n",
      "test_f1: 0.1408\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2456\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 242 Fp: 11 N: 15_977 Tn: 15_966 Fn: 2_943\n",
      "\n",
      "Metrics for test (threshold=0.92):\n",
      "test_accuracy: 0.8450\n",
      "test_precision: 0.9574\n",
      "test_recall: 0.0706\n",
      "test_f1: 0.1316\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2368\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 225 Fp: 10 N: 15_977 Tn: 15_967 Fn: 2_960\n",
      "\n",
      "Metrics for test (threshold=0.93):\n",
      "test_accuracy: 0.8443\n",
      "test_precision: 0.9631\n",
      "test_recall: 0.0656\n",
      "test_f1: 0.1229\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2291\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 209 Fp: 8 N: 15_977 Tn: 15_969 Fn: 2_976\n",
      "\n",
      "Metrics for test (threshold=0.9400000000000001):\n",
      "test_accuracy: 0.8436\n",
      "test_precision: 0.9749\n",
      "test_recall: 0.0609\n",
      "test_f1: 0.1147\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2225\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 194 Fp: 5 N: 15_977 Tn: 15_972 Fn: 2_991\n",
      "\n",
      "Metrics for test (threshold=0.9500000000000001):\n",
      "test_accuracy: 0.8422\n",
      "test_precision: 0.9708\n",
      "test_recall: 0.0521\n",
      "test_f1: 0.0989\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.2051\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 166 Fp: 5 N: 15_977 Tn: 15_972 Fn: 3_019\n",
      "\n",
      "Metrics for test (threshold=0.9600000000000001):\n",
      "test_accuracy: 0.8404\n",
      "test_precision: 0.9701\n",
      "test_recall: 0.0408\n",
      "test_f1: 0.0783\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.1812\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 130 Fp: 4 N: 15_977 Tn: 15_973 Fn: 3_055\n",
      "\n",
      "Metrics for test (threshold=0.97):\n",
      "test_accuracy: 0.8389\n",
      "test_precision: 0.9804\n",
      "test_recall: 0.0314\n",
      "test_f1: 0.0608\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.1600\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 100 Fp: 2 N: 15_977 Tn: 15_975 Fn: 3_085\n",
      "\n",
      "Metrics for test (threshold=0.98):\n",
      "test_accuracy: 0.8373\n",
      "test_precision: 0.9718\n",
      "test_recall: 0.0217\n",
      "test_f1: 0.0424\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.1320\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 69 Fp: 2 N: 15_977 Tn: 15_975 Fn: 3_116\n",
      "\n",
      "Metrics for test (threshold=0.99):\n",
      "test_accuracy: 0.8355\n",
      "test_precision: 1.0000\n",
      "test_recall: 0.0104\n",
      "test_f1: 0.0205\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.0930\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 33 Fp: 0 N: 15_977 Tn: 15_977 Fn: 3_152\n",
      "\n",
      "Metrics for test (threshold=1.0):\n",
      "test_accuracy: 0.8338\n",
      "test_precision: 0.0000\n",
      "test_recall: 0.0000\n",
      "test_f1: 0.0000\n",
      "test_roc_auc: 0.8141\n",
      "test_mcc: 0.0000\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_185 Tp: 0 Fp: 0 N: 15_977 Tn: 15_977 Fn: 3_185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spica/Repos/pici-predictor/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"n_estimators\": 10000,\n",
    "    \"max_depth\": 8,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"random_state\": 42,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "}\n",
    "\n",
    "train_function_predictor(\n",
    "    \"moron_auxiliary_metabolic_gene_and_host_takeover\", model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_params = {\n",
    "#     \"n_estimators\": 10000,\n",
    "#     \"max_depth\": 8,\n",
    "#     \"learning_rate\": 0.05,\n",
    "#     \"subsample\": 0.7,\n",
    "#     \"colsample_bytree\": 0.7,\n",
    "#     \"min_child_weight\": 2,\n",
    "#     \"random_state\": 42,\n",
    "#     \"early_stopping_rounds\": 100,\n",
    "# }\n",
    "\n",
    "# for function_name in [\n",
    "#     \"lysis\",\n",
    "#     \"tail\",\n",
    "#     \"dna_rna_and_nucleotide_metabolism\",\n",
    "#     \"head_and_packaging\",\n",
    "#     \"other\",\n",
    "#     \"transcription_regulation\",\n",
    "#     \"moron_auxiliary_metabolic_gene_and_host_takeover\",\n",
    "#     \"unknown_function\",\n",
    "#     \"integration_and_excision\",\n",
    "# ]:\n",
    "#     train_function_predictor(function_name, model_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
