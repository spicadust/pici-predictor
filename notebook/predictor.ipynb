{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "goal: train 10 machine learning predictors: one predictor for each function from the ten protein function categories (\"DNA, RNA and nucleotide metabolism\", \"tail\", \"head and packaging\", \"other\", \"lysis\", \"connector\", \"transcription regulation\", \"moron, auxiliary metabolic gene and host takeover\", \"unknown function\", \"integration and excision\") \n",
    "\n",
    "predictor input: protein features; output: labels (0/1) representing whether the protein serves the specific function\n",
    "\n",
    "dataset: 360,413 seqs in total - 60% for training, 20% for validation, 20% for testing \n",
    "** subset the negatives (samples whose label is 0) and make it about 5-10 times of the positives\n",
    "** change: split 20% for testing first, then train:val = 8:2\n",
    "\n",
    "-use clustering results to avoid spliting protein seqs in the same cluster (maybe use GroupShuffleSplit from sklearn)\n",
    "** change: for each predictor, cluster on the positive dataset (those with label \"1\") alone, and do nothing to negative dataset. use the clustering result while splitting dataset to ensure seqs in the same cluster in positive dataset is not splitted into different sets of train/val/test. I already have protein distances generated from diamond blastp in unique_diamond_results.daa, and would like to get the clustering result by select a cutoff of 100bitscore and use that to read into a graph with networkx and then extract subgraphs which then will be the clusters.\n",
    "\n",
    "** change: add learning curve for training XGBoost\n",
    "\n",
    "** change: try the 100 versions of threshold from 0.01 - 1\n",
    "\n",
    "the results are printed as text.  \n",
    "** change: not to print them out but to save it to results/predictor/{function_name}.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset:  \n",
    "2,318,538 seqs in the original dataset  \n",
    "927,040 seqs after dropping pcat \"unknown_no_hit\"  \n",
    "360,413 unique seqs after dropping duplicated seqs  \n",
    "\n",
    "features: 1711-dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subset the negatives;  \n",
    "- for each function, cluster on the positive dataset  \n",
    "- try threshold from 0.01 to 1  \n",
    "- [o] change the dataset splitting strategy  \n",
    "- [o] model param : is_imbalanced  \n",
    "- add learning curve (could be find from XGBoost)  \n",
    "- n_estimators: increased to 10k; may need GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Tuple, Dict, Any\n",
    "import joblib\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(function_name: str):\n",
    "    ids = pd.read_csv(f\"../dataset/pcat/{function_name}.csv\")\n",
    "    features = pd.read_parquet(\"../dataset/protein_features_unique.pa\")\n",
    "    features[\"label\"] = features[\"id\"].isin(ids[\"name\"]).astype(int)\n",
    "    features = features.drop(columns=[\"md5\"])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_negatives(\n",
    "    df: pd.DataFrame, label_col: str = \"label\", ratio: int = 5, random_state: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Subset the negatives to be `ratio` times the number of positives.\n",
    "    Args:\n",
    "        df: DataFrame with a label column\n",
    "        label_col: Name of the label column\n",
    "        ratio: Negative:positive ratio\n",
    "        random_state: For reproducibility\n",
    "    Returns:\n",
    "        Subsetted DataFrame\n",
    "    \"\"\"\n",
    "    pos_df = df[df[label_col] == 1]\n",
    "    neg_df = df[df[label_col] == 0]\n",
    "    n_pos = len(pos_df)\n",
    "    n_neg = min(len(neg_df), n_pos * ratio)\n",
    "    neg_df = neg_df.sample(n=n_neg, random_state=random_state)\n",
    "    return (\n",
    "        pd.concat([pos_df, neg_df])\n",
    "        .sample(frac=1, random_state=random_state)\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_positives(\n",
    "    df, bitscore_file, bitscore_cutoff=100, id_col=\"id\", label_col=\"label\"\n",
    "):\n",
    "    pos_ids = set(df[df[label_col] == 1][id_col])\n",
    "\n",
    "    # Load diamond results (parquet)\n",
    "    diamond = pd.read_parquet(bitscore_file)\n",
    "    # If needed, rename columns here:\n",
    "    # diamond = diamond.rename(columns={\"col1\": \"qseqid\", \"col2\": \"sseqid\", \"col3\": \"bitscore\"})\n",
    "\n",
    "    # Filter for bitscore cutoff and only positive IDs\n",
    "    diamond = diamond[\n",
    "        (diamond[\"bitscore\"] >= bitscore_cutoff)\n",
    "        & (diamond[\"qseqid\"].isin(pos_ids))\n",
    "        & (diamond[\"sseqid\"].isin(pos_ids))\n",
    "    ]\n",
    "\n",
    "    # Build graph\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(diamond[[\"qseqid\", \"sseqid\"]].itertuples(index=False, name=None))\n",
    "\n",
    "    # Assign cluster IDs\n",
    "    cluster_mapping = {}\n",
    "    for i, component in enumerate(nx.connected_components(G)):\n",
    "        for node in component:\n",
    "            cluster_mapping[node] = f\"cluster_{i}\"\n",
    "\n",
    "    # Assign unconnected positives to their own cluster\n",
    "    for pid in pos_ids:\n",
    "        if pid not in cluster_mapping:\n",
    "            cluster_mapping[pid] = f\"cluster_single_{pid}\"\n",
    "\n",
    "    return cluster_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: list,\n",
    "    cluster_mapping: Dict[str, str],\n",
    "    label_col: str = \"label\",\n",
    "    id_col: str = \"id\",\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Prepare data for training by separating features and labels.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame containing features and labels\n",
    "        feature_cols: List of feature column names\n",
    "        cluster_mapping: Dictionary mapping sequence IDs to cluster IDs\n",
    "        label_col: Name of the label column\n",
    "        id_col: Name of the ID column\n",
    "\n",
    "    Returns:\n",
    "        X: Feature matrix\n",
    "        y: Label array\n",
    "        ids: Array of sequence IDs\n",
    "        groups: Array of cluster IDs for each sequence\n",
    "    \"\"\"\n",
    "    X = df[feature_cols].values\n",
    "    y = df[label_col].values\n",
    "    ids = df[id_col].values\n",
    "\n",
    "    # Get cluster IDs for each sequence\n",
    "    groups = np.array([cluster_mapping.get(str(id_), \"unknown\") for id_ in ids])\n",
    "\n",
    "    return X, y, ids, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    ids: np.ndarray,\n",
    "    groups: np.ndarray,\n",
    "    test_size: float = 0.2,\n",
    "    val_size: float = 0.2,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Split data into train, validation, and test sets while keeping related sequences together.\n",
    "\n",
    "    Args:\n",
    "        X: Feature matrix\n",
    "        y: Label array\n",
    "        ids: Array of sequence IDs\n",
    "        groups: Array of cluster IDs for each sequence\n",
    "        test_size: Proportion of data to use for testing\n",
    "        val_size: Proportion of data to use for validation\n",
    "    \"\"\"\n",
    "    # First split: separate test set\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=42)\n",
    "    train_val_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "    X_train_val, X_test = X[train_val_idx], X[test_idx]\n",
    "    y_train_val, y_test = y[train_val_idx], y[test_idx]\n",
    "    groups_train_val = groups[train_val_idx]\n",
    "\n",
    "    # Second split: separate validation set from training set\n",
    "    val_size_adjusted = val_size / (\n",
    "        1 - test_size\n",
    "    )  # Adjust val_size to account for test set\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=val_size_adjusted, random_state=42)\n",
    "    train_idx, val_idx = next(\n",
    "        gss.split(X_train_val, y_train_val, groups=groups_train_val)\n",
    "    )\n",
    "\n",
    "    X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
    "    y_train, y_val = y_train_val[train_idx], y_train_val[val_idx]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# first split: test 20%\n",
    "# train:val = 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    X_val: np.ndarray,\n",
    "    y_val: np.ndarray,\n",
    "    model_params: Dict[str, Any] = None,\n",
    ") -> Tuple[Any, StandardScaler]:\n",
    "    \"\"\"Train an XGBoost classifier with optional hyperparameters.\"\"\"\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Set default parameters if none provided\n",
    "    if model_params is None:\n",
    "        model_params = {\n",
    "            \"n_estimators\": 200,\n",
    "            \"max_depth\": 6,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"subsample\": 0.8,\n",
    "            \"colsample_bytree\": 0.8,\n",
    "            \"min_child_weight\": 1,\n",
    "            \"scale_pos_weight\": 1,\n",
    "            \"random_state\": 42,\n",
    "        }\n",
    "\n",
    "    # Calculate scale_pos_weight based on class imbalance\n",
    "    n_neg = np.sum(y_train == 0)\n",
    "    n_pos = np.sum(y_train == 1)\n",
    "    model_params[\"scale_pos_weight\"] = n_neg / n_pos\n",
    "\n",
    "    # Train model\n",
    "    model = XGBClassifier(eval_metric=[\"logloss\", \"auc\"], **model_params)\n",
    "    model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        eval_set=[(X_train_scaled, y_train), (X_val_scaled, y_val)],\n",
    "        verbose=False,\n",
    "    )\n",
    "    evals_result = model.evals_result()\n",
    "    return model, scaler, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: Any,\n",
    "    scaler: StandardScaler,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    set_name: str = \"\",\n",
    "    threshold: float = 0.5,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance on a dataset.\"\"\"\n",
    "\n",
    "    # no need for scaling!\n",
    "\n",
    "    X_scaled = scaler.transform(X)\n",
    "    y_pred_proba = model.predict_proba(X_scaled)[:, 1]\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    # Calculate MCC\n",
    "    def matthews(y_true, y_pred):\n",
    "        from math import sqrt\n",
    "\n",
    "        \"\"\"\n",
    "            P  = Total number of positives\n",
    "            N  = Total number of negatives\n",
    "            Tp = number of true positives\n",
    "            Fp = number of false positives\n",
    "        \"\"\"\n",
    "        if type(y_true) == pd.Series:\n",
    "            y_true = y_true.values\n",
    "\n",
    "        P = len([x for x in y_true if x == 1])\n",
    "        N = len([x for x in y_true if x == 0])\n",
    "\n",
    "        Tp, Fp = 0, 0\n",
    "        for i in range(len(y_true)):\n",
    "            if y_true[i] == 1 and y_pred[i] == 1:\n",
    "                Tp += 1\n",
    "            elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "                Fp += 1\n",
    "\n",
    "        Tn = N - Fp\n",
    "        Fn = P - Tp\n",
    "\n",
    "        try:\n",
    "            mcc = (Tp * Tn - Fp * Fn) / sqrt(\n",
    "                (Tn + Fn) * (Tn + Fp) * (Tp + Fn) * (Tp + Fp)\n",
    "            )\n",
    "        except ZeroDivisionError:\n",
    "            mcc = 0\n",
    "        return (mcc, f\"P: {P:_} Tp: {Tp:_} Fp: {Fp:_} N: {N:_} Tn: {Tn:_} Fn: {Fn:_}\")\n",
    "\n",
    "    # Get MCC and confusion matrix values\n",
    "    mcc, confusion_str = matthews(y, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        f\"{set_name}_accuracy\": accuracy_score(y, y_pred),\n",
    "        f\"{set_name}_precision\": precision_score(y, y_pred),\n",
    "        f\"{set_name}_recall\": recall_score(y, y_pred),\n",
    "        f\"{set_name}_f1\": f1_score(y, y_pred),\n",
    "        f\"{set_name}_roc_auc\": roc_auc_score(y, y_pred_proba),\n",
    "        f\"{set_name}_mcc\": mcc,\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"\\nMetrics for {set_name} (threshold={threshold}):\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # Print confusion matrix values\n",
    "    print(f\"\\nConfusion Matrix Values:\")\n",
    "    print(confusion_str)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_feature_importance(model: Any, feature_cols: list, top_n: int = 20):\n",
    "#     \"\"\"Plot feature importance from XGBoost model.\"\"\"\n",
    "#     importance_scores = model.feature_importances_\n",
    "#     indices = np.argsort(importance_scores)[::-1]\n",
    "\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.title(\"Feature Importances\")\n",
    "#     plt.bar(range(top_n), importance_scores[indices[:top_n]])\n",
    "#     plt.xticks(range(top_n), [feature_cols[i] for i in indices[:top_n]], rotation=90)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # Print top N most important features\n",
    "#     print(f\"\\nTop {top_n} most important features:\")\n",
    "#     for i in range(top_n):\n",
    "#         print(f\"{feature_cols[indices[i]]}: {importance_scores[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(\n",
    "    model: Any, scaler: StandardScaler, feature_cols: list, function_name: str\n",
    "):\n",
    "    \"\"\"Save the trained model and scaler.\"\"\"\n",
    "    # Create models directory if it doesn't exist\n",
    "    os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "    # Create a dictionary containing all necessary components\n",
    "    model_data = {\"model\": model, \"scaler\": scaler, \"feature_cols\": feature_cols}\n",
    "\n",
    "    # Save the model data\n",
    "    joblib.dump(model_data, f\"../models/{function_name}_predictor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_function_predictor(function_name: str, model_params: Dict[str, Any] = None):\n",
    "    \"\"\"Main training pipeline for a specific protein function.\"\"\"\n",
    "    # # Load cluster mapping\n",
    "    # with open(\"../dataset/protein_cluster_mapping.json\", \"r\") as f:\n",
    "    #     cluster_mapping = json.load(f)\n",
    "\n",
    "    # get df using function name\n",
    "    df = get_df(function_name)\n",
    "    df = subset_negatives(df, ratio=5)\n",
    "\n",
    "    # Cluster positives using diamond results\n",
    "    bitscore_file = \"../dataset/unique_diamond_results.parquet\"\n",
    "    cluster_mapping = cluster_positives(df, bitscore_file, bitscore_cutoff=100)\n",
    "\n",
    "    # Assign dummy group to negatives\n",
    "    for idx, row in df.iterrows():\n",
    "        if row[\"label\"] == 0:\n",
    "            cluster_mapping[row[\"id\"]] = f\"neg_{row['id']}\"\n",
    "\n",
    "    # Get feature columns (excluding 'id' and 'label')\n",
    "    feature_cols = [col for col in df.columns if col not in [\"id\", \"label\"]]\n",
    "\n",
    "    # Prepare data\n",
    "    X, y, ids, groups = prepare_data(df, feature_cols, cluster_mapping)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y, ids, groups)\n",
    "\n",
    "    # Train model\n",
    "    model, scaler, evals_result = train_model(\n",
    "        X_train, y_train, X_val, y_val, model_params\n",
    "    )\n",
    "\n",
    "    train_metric = evals_result[\"validation_0\"][\"logloss\"]\n",
    "    val_metric = evals_result[\"validation_1\"][\"logloss\"]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_metric, label=\"Train Logloss\")\n",
    "    plt.plot(val_metric, label=\"Val Logloss\")\n",
    "    plt.xlabel(\"Boosting Round\")\n",
    "    plt.ylabel(\"Logloss\")\n",
    "    plt.title(f\"Learning Curve: {function_name}\")\n",
    "    plt.legend()\n",
    "    os.makedirs(f\"../results/predictor/learning_curves\", exist_ok=True)\n",
    "    plt.savefig(\n",
    "        f\"../results/predictor/learning_curves/{function_name}_learning_curve.png\"\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "    # Collect results in a list of strings\n",
    "    results_lines = []\n",
    "\n",
    "    # Feature importances\n",
    "    importance_scores = model.feature_importances_\n",
    "    indices = np.argsort(importance_scores)[::-1]\n",
    "    results_lines.append(\"Top 20 most important features:\")\n",
    "    for i in range(20):\n",
    "        results_lines.append(\n",
    "            f\"{feature_cols[indices[i]]}: {importance_scores[indices[i]]:.4f}\"\n",
    "        )\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Train metrics\n",
    "    train_metrics = evaluate_model(model, scaler, X_train, y_train, \"train\")\n",
    "    results_lines.append(\"=== Training Set ===\")\n",
    "    for k, v in train_metrics.items():\n",
    "        results_lines.append(f\"{k}: {v}\")\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Validation metrics\n",
    "    val_metrics = evaluate_model(model, scaler, X_val, y_val, \"val\")\n",
    "    results_lines.append(\"=== Validation Set ===\")\n",
    "    for k, v in val_metrics.items():\n",
    "        results_lines.append(f\"{k}: {v}\")\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Test metrics for all thresholds\n",
    "    results_lines.append(\"=== Test Set ===\")\n",
    "    thresholds = np.linspace(0.01, 1.0, 100)\n",
    "    best_mcc = -float(\"inf\")\n",
    "    best_threshold = None\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        test_metrics = evaluate_model(model, scaler, X_test, y_test, \"test\", threshold)\n",
    "        results_lines.append(f\"Threshold: {threshold:.2f}\")\n",
    "        for k, v in test_metrics.items():\n",
    "            results_lines.append(f\"{k}: {v}\")\n",
    "        results_lines.append(\"\")\n",
    "        # Track best MCC\n",
    "        mcc = test_metrics.get(\"test_mcc\", -float(\"inf\"))\n",
    "        if isinstance(\n",
    "            mcc, tuple\n",
    "        ):  # If your evaluate_model returns (mcc, confusion_str)\n",
    "            mcc = mcc[0]\n",
    "        if mcc > best_mcc:\n",
    "            best_mcc = mcc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    # Add the best MCC summary line\n",
    "    results_lines.append(f\"Best MCC: {best_mcc:.4f} at threshold {best_threshold:.2f}\")\n",
    "    results_lines.append(\"\")\n",
    "\n",
    "    # Save all results to file\n",
    "    os.makedirs(\"../results/predictor\", exist_ok=True)\n",
    "    result_file = f\"../results/predictor/{function_name}.txt\"\n",
    "    with open(result_file, \"w\") as f:\n",
    "        f.write(\"\\n\".join(results_lines))\n",
    "\n",
    "    # Save model\n",
    "    save_model(model, scaler, feature_cols, function_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for train (threshold=0.5):\n",
      "train_accuracy: 1.0000\n",
      "train_precision: 1.0000\n",
      "train_recall: 1.0000\n",
      "train_f1: 1.0000\n",
      "train_roc_auc: 1.0000\n",
      "train_mcc: 1.0000\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 15_298 Tp: 15_298 Fp: 0 N: 61_405 Tn: 61_405 Fn: 0\n",
      "\n",
      "Metrics for val (threshold=0.5):\n",
      "val_accuracy: 0.9619\n",
      "val_precision: 0.9479\n",
      "val_recall: 0.6111\n",
      "val_f1: 0.7431\n",
      "val_roc_auc: 0.9709\n",
      "val_mcc: 0.7440\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 2_026 Tp: 1_238 Fp: 68 N: 20_454 Tn: 20_386 Fn: 788\n",
      "\n",
      "Metrics for test (threshold=0.01):\n",
      "test_accuracy: 0.9397\n",
      "test_precision: 0.7771\n",
      "test_recall: 0.7667\n",
      "test_f1: 0.7719\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7372\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 2_406 Fp: 690 N: 20_451 Tn: 19_761 Fn: 732\n",
      "\n",
      "Metrics for test (threshold=0.02):\n",
      "test_accuracy: 0.9431\n",
      "test_precision: 0.8237\n",
      "test_recall: 0.7279\n",
      "test_f1: 0.7728\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7422\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 2_284 Fp: 489 N: 20_451 Tn: 19_962 Fn: 854\n",
      "\n",
      "Metrics for test (threshold=0.03):\n",
      "test_accuracy: 0.9425\n",
      "test_precision: 0.8440\n",
      "test_recall: 0.6963\n",
      "test_f1: 0.7631\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7350\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 2_185 Fp: 404 N: 20_451 Tn: 20_047 Fn: 953\n",
      "\n",
      "Metrics for test (threshold=0.04):\n",
      "test_accuracy: 0.9423\n",
      "test_precision: 0.8573\n",
      "test_recall: 0.6797\n",
      "test_f1: 0.7583\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7323\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 2_133 Fp: 355 N: 20_451 Tn: 20_096 Fn: 1_005\n",
      "\n",
      "Metrics for test (threshold=0.05):\n",
      "test_accuracy: 0.9417\n",
      "test_precision: 0.8674\n",
      "test_recall: 0.6632\n",
      "test_f1: 0.7517\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7276\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 2_081 Fp: 318 N: 20_451 Tn: 20_133 Fn: 1_057\n",
      "\n",
      "Metrics for test (threshold=0.060000000000000005):\n",
      "test_accuracy: 0.9413\n",
      "test_precision: 0.8741\n",
      "test_recall: 0.6526\n",
      "test_f1: 0.7473\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7247\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 2_048 Fp: 295 N: 20_451 Tn: 20_156 Fn: 1_090\n",
      "\n",
      "Metrics for test (threshold=0.06999999999999999):\n",
      "test_accuracy: 0.9407\n",
      "test_precision: 0.8786\n",
      "test_recall: 0.6434\n",
      "test_f1: 0.7428\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7213\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 2_019 Fp: 279 N: 20_451 Tn: 20_172 Fn: 1_119\n",
      "\n",
      "Metrics for test (threshold=0.08):\n",
      "test_accuracy: 0.9404\n",
      "test_precision: 0.8832\n",
      "test_recall: 0.6364\n",
      "test_f1: 0.7398\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7193\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_997 Fp: 264 N: 20_451 Tn: 20_187 Fn: 1_141\n",
      "\n",
      "Metrics for test (threshold=0.09):\n",
      "test_accuracy: 0.9403\n",
      "test_precision: 0.8889\n",
      "test_recall: 0.6300\n",
      "test_f1: 0.7374\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7181\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_977 Fp: 247 N: 20_451 Tn: 20_204 Fn: 1_161\n",
      "\n",
      "Metrics for test (threshold=0.09999999999999999):\n",
      "test_accuracy: 0.9396\n",
      "test_precision: 0.8935\n",
      "test_recall: 0.6201\n",
      "test_f1: 0.7321\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7142\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_946 Fp: 232 N: 20_451 Tn: 20_219 Fn: 1_192\n",
      "\n",
      "Metrics for test (threshold=0.11):\n",
      "test_accuracy: 0.9390\n",
      "test_precision: 0.8942\n",
      "test_recall: 0.6144\n",
      "test_f1: 0.7284\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7109\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_928 Fp: 228 N: 20_451 Tn: 20_223 Fn: 1_210\n",
      "\n",
      "Metrics for test (threshold=0.12):\n",
      "test_accuracy: 0.9387\n",
      "test_precision: 0.8972\n",
      "test_recall: 0.6090\n",
      "test_f1: 0.7255\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7089\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_911 Fp: 219 N: 20_451 Tn: 20_232 Fn: 1_227\n",
      "\n",
      "Metrics for test (threshold=0.13):\n",
      "test_accuracy: 0.9383\n",
      "test_precision: 0.8997\n",
      "test_recall: 0.6033\n",
      "test_f1: 0.7222\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7065\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_893 Fp: 211 N: 20_451 Tn: 20_240 Fn: 1_245\n",
      "\n",
      "Metrics for test (threshold=0.14):\n",
      "test_accuracy: 0.9379\n",
      "test_precision: 0.9024\n",
      "test_recall: 0.5978\n",
      "test_f1: 0.7192\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7043\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_876 Fp: 203 N: 20_451 Tn: 20_248 Fn: 1_262\n",
      "\n",
      "Metrics for test (threshold=0.15000000000000002):\n",
      "test_accuracy: 0.9379\n",
      "test_precision: 0.9051\n",
      "test_recall: 0.5956\n",
      "test_f1: 0.7184\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7042\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_869 Fp: 196 N: 20_451 Tn: 20_255 Fn: 1_269\n",
      "\n",
      "Metrics for test (threshold=0.16):\n",
      "test_accuracy: 0.9376\n",
      "test_precision: 0.9067\n",
      "test_recall: 0.5918\n",
      "test_f1: 0.7162\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7025\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_857 Fp: 191 N: 20_451 Tn: 20_260 Fn: 1_281\n",
      "\n",
      "Metrics for test (threshold=0.17):\n",
      "test_accuracy: 0.9372\n",
      "test_precision: 0.9063\n",
      "test_recall: 0.5886\n",
      "test_f1: 0.7137\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.7002\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_847 Fp: 191 N: 20_451 Tn: 20_260 Fn: 1_291\n",
      "\n",
      "Metrics for test (threshold=0.18000000000000002):\n",
      "test_accuracy: 0.9365\n",
      "test_precision: 0.9072\n",
      "test_recall: 0.5825\n",
      "test_f1: 0.7095\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6967\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_828 Fp: 187 N: 20_451 Tn: 20_264 Fn: 1_310\n",
      "\n",
      "Metrics for test (threshold=0.19):\n",
      "test_accuracy: 0.9362\n",
      "test_precision: 0.9089\n",
      "test_recall: 0.5784\n",
      "test_f1: 0.7069\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6948\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_815 Fp: 182 N: 20_451 Tn: 20_269 Fn: 1_323\n",
      "\n",
      "Metrics for test (threshold=0.2):\n",
      "test_accuracy: 0.9354\n",
      "test_precision: 0.9088\n",
      "test_recall: 0.5717\n",
      "test_f1: 0.7019\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6903\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_794 Fp: 180 N: 20_451 Tn: 20_271 Fn: 1_344\n",
      "\n",
      "Metrics for test (threshold=0.21000000000000002):\n",
      "test_accuracy: 0.9351\n",
      "test_precision: 0.9119\n",
      "test_recall: 0.5672\n",
      "test_f1: 0.6994\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6889\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_780 Fp: 172 N: 20_451 Tn: 20_279 Fn: 1_358\n",
      "\n",
      "Metrics for test (threshold=0.22):\n",
      "test_accuracy: 0.9349\n",
      "test_precision: 0.9134\n",
      "test_recall: 0.5644\n",
      "test_f1: 0.6977\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6876\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_771 Fp: 168 N: 20_451 Tn: 20_283 Fn: 1_367\n",
      "\n",
      "Metrics for test (threshold=0.23):\n",
      "test_accuracy: 0.9348\n",
      "test_precision: 0.9145\n",
      "test_recall: 0.5625\n",
      "test_f1: 0.6965\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6869\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_765 Fp: 165 N: 20_451 Tn: 20_286 Fn: 1_373\n",
      "\n",
      "Metrics for test (threshold=0.24000000000000002):\n",
      "test_accuracy: 0.9344\n",
      "test_precision: 0.9162\n",
      "test_recall: 0.5577\n",
      "test_f1: 0.6933\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6845\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_750 Fp: 160 N: 20_451 Tn: 20_291 Fn: 1_388\n",
      "\n",
      "Metrics for test (threshold=0.25):\n",
      "test_accuracy: 0.9342\n",
      "test_precision: 0.9205\n",
      "test_recall: 0.5532\n",
      "test_f1: 0.6911\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6835\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_736 Fp: 150 N: 20_451 Tn: 20_301 Fn: 1_402\n",
      "\n",
      "Metrics for test (threshold=0.26):\n",
      "test_accuracy: 0.9337\n",
      "test_precision: 0.9209\n",
      "test_recall: 0.5488\n",
      "test_f1: 0.6877\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6807\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_722 Fp: 148 N: 20_451 Tn: 20_303 Fn: 1_416\n",
      "\n",
      "Metrics for test (threshold=0.27):\n",
      "test_accuracy: 0.9335\n",
      "test_precision: 0.9225\n",
      "test_recall: 0.5462\n",
      "test_f1: 0.6861\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6797\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_714 Fp: 144 N: 20_451 Tn: 20_307 Fn: 1_424\n",
      "\n",
      "Metrics for test (threshold=0.28):\n",
      "test_accuracy: 0.9329\n",
      "test_precision: 0.9228\n",
      "test_recall: 0.5411\n",
      "test_f1: 0.6822\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6764\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_698 Fp: 142 N: 20_451 Tn: 20_309 Fn: 1_440\n",
      "\n",
      "Metrics for test (threshold=0.29000000000000004):\n",
      "test_accuracy: 0.9325\n",
      "test_precision: 0.9238\n",
      "test_recall: 0.5370\n",
      "test_f1: 0.6792\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6741\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_685 Fp: 139 N: 20_451 Tn: 20_312 Fn: 1_453\n",
      "\n",
      "Metrics for test (threshold=0.3):\n",
      "test_accuracy: 0.9324\n",
      "test_precision: 0.9256\n",
      "test_recall: 0.5351\n",
      "test_f1: 0.6781\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6736\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_679 Fp: 135 N: 20_451 Tn: 20_316 Fn: 1_459\n",
      "\n",
      "Metrics for test (threshold=0.31):\n",
      "test_accuracy: 0.9322\n",
      "test_precision: 0.9263\n",
      "test_recall: 0.5328\n",
      "test_f1: 0.6765\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6724\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_672 Fp: 133 N: 20_451 Tn: 20_318 Fn: 1_466\n",
      "\n",
      "Metrics for test (threshold=0.32):\n",
      "test_accuracy: 0.9319\n",
      "test_precision: 0.9270\n",
      "test_recall: 0.5300\n",
      "test_f1: 0.6744\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6707\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_663 Fp: 131 N: 20_451 Tn: 20_320 Fn: 1_475\n",
      "\n",
      "Metrics for test (threshold=0.33):\n",
      "test_accuracy: 0.9314\n",
      "test_precision: 0.9269\n",
      "test_recall: 0.5255\n",
      "test_f1: 0.6707\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6677\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_649 Fp: 130 N: 20_451 Tn: 20_321 Fn: 1_489\n",
      "\n",
      "Metrics for test (threshold=0.34):\n",
      "test_accuracy: 0.9310\n",
      "test_precision: 0.9285\n",
      "test_recall: 0.5214\n",
      "test_f1: 0.6678\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6655\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_636 Fp: 126 N: 20_451 Tn: 20_325 Fn: 1_502\n",
      "\n",
      "Metrics for test (threshold=0.35000000000000003):\n",
      "test_accuracy: 0.9306\n",
      "test_precision: 0.9291\n",
      "test_recall: 0.5175\n",
      "test_f1: 0.6648\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6631\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_624 Fp: 124 N: 20_451 Tn: 20_327 Fn: 1_514\n",
      "\n",
      "Metrics for test (threshold=0.36000000000000004):\n",
      "test_accuracy: 0.9303\n",
      "test_precision: 0.9298\n",
      "test_recall: 0.5147\n",
      "test_f1: 0.6626\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6614\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_615 Fp: 122 N: 20_451 Tn: 20_329 Fn: 1_523\n",
      "\n",
      "Metrics for test (threshold=0.37):\n",
      "test_accuracy: 0.9300\n",
      "test_precision: 0.9305\n",
      "test_recall: 0.5121\n",
      "test_f1: 0.6606\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6600\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_607 Fp: 120 N: 20_451 Tn: 20_331 Fn: 1_531\n",
      "\n",
      "Metrics for test (threshold=0.38):\n",
      "test_accuracy: 0.9298\n",
      "test_precision: 0.9319\n",
      "test_recall: 0.5099\n",
      "test_f1: 0.6591\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6591\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_600 Fp: 117 N: 20_451 Tn: 20_334 Fn: 1_538\n",
      "\n",
      "Metrics for test (threshold=0.39):\n",
      "test_accuracy: 0.9292\n",
      "test_precision: 0.9312\n",
      "test_recall: 0.5048\n",
      "test_f1: 0.6547\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6552\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_584 Fp: 117 N: 20_451 Tn: 20_334 Fn: 1_554\n",
      "\n",
      "Metrics for test (threshold=0.4):\n",
      "test_accuracy: 0.9289\n",
      "test_precision: 0.9340\n",
      "test_recall: 0.5010\n",
      "test_f1: 0.6521\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6538\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_572 Fp: 111 N: 20_451 Tn: 20_340 Fn: 1_566\n",
      "\n",
      "Metrics for test (threshold=0.41000000000000003):\n",
      "test_accuracy: 0.9286\n",
      "test_precision: 0.9343\n",
      "test_recall: 0.4984\n",
      "test_f1: 0.6500\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6521\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_564 Fp: 110 N: 20_451 Tn: 20_341 Fn: 1_574\n",
      "\n",
      "Metrics for test (threshold=0.42000000000000004):\n",
      "test_accuracy: 0.9282\n",
      "test_precision: 0.9339\n",
      "test_recall: 0.4952\n",
      "test_f1: 0.6472\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6497\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_554 Fp: 110 N: 20_451 Tn: 20_341 Fn: 1_584\n",
      "\n",
      "Metrics for test (threshold=0.43):\n",
      "test_accuracy: 0.9278\n",
      "test_precision: 0.9345\n",
      "test_recall: 0.4914\n",
      "test_f1: 0.6441\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6473\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_542 Fp: 108 N: 20_451 Tn: 20_343 Fn: 1_596\n",
      "\n",
      "Metrics for test (threshold=0.44):\n",
      "test_accuracy: 0.9275\n",
      "test_precision: 0.9348\n",
      "test_recall: 0.4892\n",
      "test_f1: 0.6423\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6458\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_535 Fp: 107 N: 20_451 Tn: 20_344 Fn: 1_603\n",
      "\n",
      "Metrics for test (threshold=0.45):\n",
      "test_accuracy: 0.9270\n",
      "test_precision: 0.9349\n",
      "test_recall: 0.4850\n",
      "test_f1: 0.6387\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6429\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_522 Fp: 106 N: 20_451 Tn: 20_345 Fn: 1_616\n",
      "\n",
      "Metrics for test (threshold=0.46):\n",
      "test_accuracy: 0.9265\n",
      "test_precision: 0.9355\n",
      "test_recall: 0.4809\n",
      "test_f1: 0.6352\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6402\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_509 Fp: 104 N: 20_451 Tn: 20_347 Fn: 1_629\n",
      "\n",
      "Metrics for test (threshold=0.47000000000000003):\n",
      "test_accuracy: 0.9262\n",
      "test_precision: 0.9357\n",
      "test_recall: 0.4780\n",
      "test_f1: 0.6328\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6382\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_500 Fp: 103 N: 20_451 Tn: 20_348 Fn: 1_638\n",
      "\n",
      "Metrics for test (threshold=0.48000000000000004):\n",
      "test_accuracy: 0.9258\n",
      "test_precision: 0.9364\n",
      "test_recall: 0.4742\n",
      "test_f1: 0.6296\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6358\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_488 Fp: 101 N: 20_451 Tn: 20_350 Fn: 1_650\n",
      "\n",
      "Metrics for test (threshold=0.49):\n",
      "test_accuracy: 0.9255\n",
      "test_precision: 0.9362\n",
      "test_recall: 0.4723\n",
      "test_f1: 0.6278\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6343\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_482 Fp: 101 N: 20_451 Tn: 20_350 Fn: 1_656\n",
      "\n",
      "Metrics for test (threshold=0.5):\n",
      "test_accuracy: 0.9249\n",
      "test_precision: 0.9356\n",
      "test_recall: 0.4675\n",
      "test_f1: 0.6235\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6306\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_467 Fp: 101 N: 20_451 Tn: 20_350 Fn: 1_671\n",
      "\n",
      "Metrics for test (threshold=0.51):\n",
      "test_accuracy: 0.9247\n",
      "test_precision: 0.9365\n",
      "test_recall: 0.4653\n",
      "test_f1: 0.6217\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6294\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_460 Fp: 99 N: 20_451 Tn: 20_352 Fn: 1_678\n",
      "\n",
      "Metrics for test (threshold=0.52):\n",
      "test_accuracy: 0.9243\n",
      "test_precision: 0.9367\n",
      "test_recall: 0.4621\n",
      "test_f1: 0.6189\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6271\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_450 Fp: 98 N: 20_451 Tn: 20_353 Fn: 1_688\n",
      "\n",
      "Metrics for test (threshold=0.53):\n",
      "test_accuracy: 0.9239\n",
      "test_precision: 0.9374\n",
      "test_recall: 0.4583\n",
      "test_f1: 0.6156\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6247\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_438 Fp: 96 N: 20_451 Tn: 20_355 Fn: 1_700\n",
      "\n",
      "Metrics for test (threshold=0.54):\n",
      "test_accuracy: 0.9233\n",
      "test_precision: 0.9386\n",
      "test_recall: 0.4532\n",
      "test_f1: 0.6112\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6214\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_422 Fp: 93 N: 20_451 Tn: 20_358 Fn: 1_716\n",
      "\n",
      "Metrics for test (threshold=0.55):\n",
      "test_accuracy: 0.9229\n",
      "test_precision: 0.9388\n",
      "test_recall: 0.4496\n",
      "test_f1: 0.6081\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6189\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_411 Fp: 92 N: 20_451 Tn: 20_359 Fn: 1_727\n",
      "\n",
      "Metrics for test (threshold=0.56):\n",
      "test_accuracy: 0.9224\n",
      "test_precision: 0.9383\n",
      "test_recall: 0.4458\n",
      "test_f1: 0.6045\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6159\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_399 Fp: 92 N: 20_451 Tn: 20_359 Fn: 1_739\n",
      "\n",
      "Metrics for test (threshold=0.5700000000000001):\n",
      "test_accuracy: 0.9220\n",
      "test_precision: 0.9386\n",
      "test_recall: 0.4430\n",
      "test_f1: 0.6019\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6139\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_390 Fp: 91 N: 20_451 Tn: 20_360 Fn: 1_748\n",
      "\n",
      "Metrics for test (threshold=0.5800000000000001):\n",
      "test_accuracy: 0.9217\n",
      "test_precision: 0.9400\n",
      "test_recall: 0.4395\n",
      "test_f1: 0.5989\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6119\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_379 Fp: 88 N: 20_451 Tn: 20_363 Fn: 1_759\n",
      "\n",
      "Metrics for test (threshold=0.59):\n",
      "test_accuracy: 0.9212\n",
      "test_precision: 0.9395\n",
      "test_recall: 0.4356\n",
      "test_f1: 0.5953\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6089\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_367 Fp: 88 N: 20_451 Tn: 20_363 Fn: 1_771\n",
      "\n",
      "Metrics for test (threshold=0.6):\n",
      "test_accuracy: 0.9205\n",
      "test_precision: 0.9388\n",
      "test_recall: 0.4302\n",
      "test_f1: 0.5900\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6045\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_350 Fp: 88 N: 20_451 Tn: 20_363 Fn: 1_788\n",
      "\n",
      "Metrics for test (threshold=0.61):\n",
      "test_accuracy: 0.9199\n",
      "test_precision: 0.9388\n",
      "test_recall: 0.4254\n",
      "test_f1: 0.5855\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.6010\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_335 Fp: 87 N: 20_451 Tn: 20_364 Fn: 1_803\n",
      "\n",
      "Metrics for test (threshold=0.62):\n",
      "test_accuracy: 0.9192\n",
      "test_precision: 0.9382\n",
      "test_recall: 0.4207\n",
      "test_f1: 0.5809\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5971\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_320 Fp: 87 N: 20_451 Tn: 20_364 Fn: 1_818\n",
      "\n",
      "Metrics for test (threshold=0.63):\n",
      "test_accuracy: 0.9185\n",
      "test_precision: 0.9374\n",
      "test_recall: 0.4149\n",
      "test_f1: 0.5752\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5924\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_302 Fp: 87 N: 20_451 Tn: 20_364 Fn: 1_836\n",
      "\n",
      "Metrics for test (threshold=0.64):\n",
      "test_accuracy: 0.9179\n",
      "test_precision: 0.9380\n",
      "test_recall: 0.4101\n",
      "test_f1: 0.5707\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5891\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_287 Fp: 85 N: 20_451 Tn: 20_366 Fn: 1_851\n",
      "\n",
      "Metrics for test (threshold=0.65):\n",
      "test_accuracy: 0.9176\n",
      "test_precision: 0.9403\n",
      "test_recall: 0.4066\n",
      "test_f1: 0.5677\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5873\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_276 Fp: 81 N: 20_451 Tn: 20_370 Fn: 1_862\n",
      "\n",
      "Metrics for test (threshold=0.66):\n",
      "test_accuracy: 0.9173\n",
      "test_precision: 0.9420\n",
      "test_recall: 0.4034\n",
      "test_f1: 0.5649\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5855\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_266 Fp: 78 N: 20_451 Tn: 20_373 Fn: 1_872\n",
      "\n",
      "Metrics for test (threshold=0.67):\n",
      "test_accuracy: 0.9170\n",
      "test_precision: 0.9443\n",
      "test_recall: 0.3999\n",
      "test_f1: 0.5619\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5837\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_255 Fp: 74 N: 20_451 Tn: 20_377 Fn: 1_883\n",
      "\n",
      "Metrics for test (threshold=0.68):\n",
      "test_accuracy: 0.9166\n",
      "test_precision: 0.9452\n",
      "test_recall: 0.3958\n",
      "test_f1: 0.5580\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5809\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_242 Fp: 72 N: 20_451 Tn: 20_379 Fn: 1_896\n",
      "\n",
      "Metrics for test (threshold=0.6900000000000001):\n",
      "test_accuracy: 0.9160\n",
      "test_precision: 0.9453\n",
      "test_recall: 0.3913\n",
      "test_f1: 0.5535\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5774\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_228 Fp: 71 N: 20_451 Tn: 20_380 Fn: 1_910\n",
      "\n",
      "Metrics for test (threshold=0.7000000000000001):\n",
      "test_accuracy: 0.9159\n",
      "test_precision: 0.9466\n",
      "test_recall: 0.3894\n",
      "test_f1: 0.5518\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5764\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_222 Fp: 69 N: 20_451 Tn: 20_382 Fn: 1_916\n",
      "\n",
      "Metrics for test (threshold=0.7100000000000001):\n",
      "test_accuracy: 0.9155\n",
      "test_precision: 0.9462\n",
      "test_recall: 0.3866\n",
      "test_f1: 0.5489\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5740\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_213 Fp: 69 N: 20_451 Tn: 20_382 Fn: 1_925\n",
      "\n",
      "Metrics for test (threshold=0.72):\n",
      "test_accuracy: 0.9150\n",
      "test_precision: 0.9465\n",
      "test_recall: 0.3830\n",
      "test_f1: 0.5454\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5714\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_202 Fp: 68 N: 20_451 Tn: 20_383 Fn: 1_936\n",
      "\n",
      "Metrics for test (threshold=0.73):\n",
      "test_accuracy: 0.9147\n",
      "test_precision: 0.9468\n",
      "test_recall: 0.3802\n",
      "test_f1: 0.5425\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5692\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_193 Fp: 67 N: 20_451 Tn: 20_384 Fn: 1_945\n",
      "\n",
      "Metrics for test (threshold=0.74):\n",
      "test_accuracy: 0.9143\n",
      "test_precision: 0.9486\n",
      "test_recall: 0.3764\n",
      "test_f1: 0.5389\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5669\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_181 Fp: 64 N: 20_451 Tn: 20_387 Fn: 1_957\n",
      "\n",
      "Metrics for test (threshold=0.75):\n",
      "test_accuracy: 0.9140\n",
      "test_precision: 0.9490\n",
      "test_recall: 0.3738\n",
      "test_f1: 0.5364\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5650\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_173 Fp: 63 N: 20_451 Tn: 20_388 Fn: 1_965\n",
      "\n",
      "Metrics for test (threshold=0.76):\n",
      "test_accuracy: 0.9136\n",
      "test_precision: 0.9509\n",
      "test_recall: 0.3700\n",
      "test_f1: 0.5327\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5626\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_161 Fp: 60 N: 20_451 Tn: 20_391 Fn: 1_977\n",
      "\n",
      "Metrics for test (threshold=0.77):\n",
      "test_accuracy: 0.9133\n",
      "test_precision: 0.9520\n",
      "test_recall: 0.3668\n",
      "test_f1: 0.5296\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5605\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_151 Fp: 58 N: 20_451 Tn: 20_393 Fn: 1_987\n",
      "\n",
      "Metrics for test (threshold=0.78):\n",
      "test_accuracy: 0.9126\n",
      "test_precision: 0.9536\n",
      "test_recall: 0.3604\n",
      "test_f1: 0.5231\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5560\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_131 Fp: 55 N: 20_451 Tn: 20_396 Fn: 2_007\n",
      "\n",
      "Metrics for test (threshold=0.79):\n",
      "test_accuracy: 0.9121\n",
      "test_precision: 0.9563\n",
      "test_recall: 0.3556\n",
      "test_f1: 0.5185\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5531\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_116 Fp: 51 N: 20_451 Tn: 20_400 Fn: 2_022\n",
      "\n",
      "Metrics for test (threshold=0.8):\n",
      "test_accuracy: 0.9114\n",
      "test_precision: 0.9565\n",
      "test_recall: 0.3502\n",
      "test_f1: 0.5127\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5487\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_099 Fp: 50 N: 20_451 Tn: 20_401 Fn: 2_039\n",
      "\n",
      "Metrics for test (threshold=0.81):\n",
      "test_accuracy: 0.9110\n",
      "test_precision: 0.9585\n",
      "test_recall: 0.3461\n",
      "test_f1: 0.5085\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5460\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_086 Fp: 47 N: 20_451 Tn: 20_404 Fn: 2_052\n",
      "\n",
      "Metrics for test (threshold=0.8200000000000001):\n",
      "test_accuracy: 0.9106\n",
      "test_precision: 0.9597\n",
      "test_recall: 0.3419\n",
      "test_f1: 0.5042\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5430\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_073 Fp: 45 N: 20_451 Tn: 20_406 Fn: 2_065\n",
      "\n",
      "Metrics for test (threshold=0.8300000000000001):\n",
      "test_accuracy: 0.9100\n",
      "test_precision: 0.9610\n",
      "test_recall: 0.3375\n",
      "test_f1: 0.4995\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5397\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_059 Fp: 43 N: 20_451 Tn: 20_408 Fn: 2_079\n",
      "\n",
      "Metrics for test (threshold=0.8400000000000001):\n",
      "test_accuracy: 0.9095\n",
      "test_precision: 0.9622\n",
      "test_recall: 0.3327\n",
      "test_f1: 0.4944\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5361\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_044 Fp: 41 N: 20_451 Tn: 20_410 Fn: 2_094\n",
      "\n",
      "Metrics for test (threshold=0.85):\n",
      "test_accuracy: 0.9090\n",
      "test_precision: 0.9627\n",
      "test_recall: 0.3286\n",
      "test_f1: 0.4899\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5328\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_031 Fp: 40 N: 20_451 Tn: 20_411 Fn: 2_107\n",
      "\n",
      "Metrics for test (threshold=0.86):\n",
      "test_accuracy: 0.9083\n",
      "test_precision: 0.9629\n",
      "test_recall: 0.3228\n",
      "test_f1: 0.4835\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5280\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 1_013 Fp: 39 N: 20_451 Tn: 20_412 Fn: 2_125\n",
      "\n",
      "Metrics for test (threshold=0.87):\n",
      "test_accuracy: 0.9075\n",
      "test_precision: 0.9622\n",
      "test_recall: 0.3168\n",
      "test_f1: 0.4766\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5225\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 994 Fp: 39 N: 20_451 Tn: 20_412 Fn: 2_144\n",
      "\n",
      "Metrics for test (threshold=0.88):\n",
      "test_accuracy: 0.9068\n",
      "test_precision: 0.9644\n",
      "test_recall: 0.3110\n",
      "test_f1: 0.4704\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5183\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 976 Fp: 36 N: 20_451 Tn: 20_415 Fn: 2_162\n",
      "\n",
      "Metrics for test (threshold=0.89):\n",
      "test_accuracy: 0.9061\n",
      "test_precision: 0.9666\n",
      "test_recall: 0.3047\n",
      "test_f1: 0.4633\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5135\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 956 Fp: 33 N: 20_451 Tn: 20_418 Fn: 2_182\n",
      "\n",
      "Metrics for test (threshold=0.9):\n",
      "test_accuracy: 0.9050\n",
      "test_precision: 0.9677\n",
      "test_recall: 0.2960\n",
      "test_f1: 0.4534\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5062\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 929 Fp: 31 N: 20_451 Tn: 20_420 Fn: 2_209\n",
      "\n",
      "Metrics for test (threshold=0.91):\n",
      "test_accuracy: 0.9042\n",
      "test_precision: 0.9690\n",
      "test_recall: 0.2890\n",
      "test_f1: 0.4453\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.5004\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 907 Fp: 29 N: 20_451 Tn: 20_422 Fn: 2_231\n",
      "\n",
      "Metrics for test (threshold=0.92):\n",
      "test_accuracy: 0.9029\n",
      "test_precision: 0.9711\n",
      "test_recall: 0.2782\n",
      "test_f1: 0.4325\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.4912\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 873 Fp: 26 N: 20_451 Tn: 20_425 Fn: 2_265\n",
      "\n",
      "Metrics for test (threshold=0.93):\n",
      "test_accuracy: 0.9011\n",
      "test_precision: 0.9719\n",
      "test_recall: 0.2645\n",
      "test_f1: 0.4158\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.4787\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 830 Fp: 24 N: 20_451 Tn: 20_427 Fn: 2_308\n",
      "\n",
      "Metrics for test (threshold=0.9400000000000001):\n",
      "test_accuracy: 0.8999\n",
      "test_precision: 0.9732\n",
      "test_recall: 0.2546\n",
      "test_f1: 0.4036\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.4698\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 799 Fp: 22 N: 20_451 Tn: 20_429 Fn: 2_339\n",
      "\n",
      "Metrics for test (threshold=0.9500000000000001):\n",
      "test_accuracy: 0.8982\n",
      "test_precision: 0.9730\n",
      "test_recall: 0.2412\n",
      "test_f1: 0.3866\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.4568\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 757 Fp: 21 N: 20_451 Tn: 20_430 Fn: 2_381\n",
      "\n",
      "Metrics for test (threshold=0.9600000000000001):\n",
      "test_accuracy: 0.8963\n",
      "test_precision: 0.9806\n",
      "test_recall: 0.2253\n",
      "test_f1: 0.3664\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.4431\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 707 Fp: 14 N: 20_451 Tn: 20_437 Fn: 2_431\n",
      "\n",
      "Metrics for test (threshold=0.97):\n",
      "test_accuracy: 0.8943\n",
      "test_precision: 0.9821\n",
      "test_recall: 0.2094\n",
      "test_f1: 0.3452\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.4271\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 657 Fp: 12 N: 20_451 Tn: 20_439 Fn: 2_481\n",
      "\n",
      "Metrics for test (threshold=0.98):\n",
      "test_accuracy: 0.8915\n",
      "test_precision: 0.9817\n",
      "test_recall: 0.1877\n",
      "test_f1: 0.3151\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.4037\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 589 Fp: 11 N: 20_451 Tn: 20_440 Fn: 2_549\n",
      "\n",
      "Metrics for test (threshold=0.99):\n",
      "test_accuracy: 0.8880\n",
      "test_precision: 0.9921\n",
      "test_recall: 0.1597\n",
      "test_f1: 0.2750\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.3741\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 501 Fp: 4 N: 20_451 Tn: 20_447 Fn: 2_637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spica/Repos/pici-predictor/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for test (threshold=1.0):\n",
      "test_accuracy: 0.8670\n",
      "test_precision: 0.0000\n",
      "test_recall: 0.0000\n",
      "test_f1: 0.0000\n",
      "test_roc_auc: 0.9600\n",
      "test_mcc: 0.0000\n",
      "\n",
      "Confusion Matrix Values:\n",
      "P: 3_138 Tp: 0 Fp: 0 N: 20_451 Tn: 20_451 Fn: 3_138\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "    \"n_estimators\": 10000,\n",
    "    \"max_depth\": 8,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"subsample\": 0.7,\n",
    "    \"colsample_bytree\": 0.7,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "train_function_predictor(\"lysis\", model_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
