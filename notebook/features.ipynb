{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from feature_generation import seq2features, create_genomic_features\n",
    "import warnings\n",
    "from Bio import BiopythonDeprecationWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=BiopythonDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sequences(fasta_file):\n",
    "    # Count lines to estimate number of sequences (optional, for better progress bar)\n",
    "    with open(fasta_file, \"r\") as f:\n",
    "        n_seqs = sum(1 for line in f if line.startswith(\">\"))\n",
    "\n",
    "    with open(fasta_file, \"r\") as f:\n",
    "        entries = [\n",
    "            (name, seq)\n",
    "            for name, seq in tqdm(\n",
    "                SimpleFastaParser(f), total=n_seqs, desc=\"Loading sequences\"\n",
    "            )\n",
    "        ]\n",
    "    return entries\n",
    "\n",
    "\n",
    "def generate_features(entries, is_dna=False, chunk_size=None):\n",
    "    if chunk_size is None:\n",
    "        # Original behavior\n",
    "        if is_dna:\n",
    "            features_df = create_genomic_features(\"your_dna.fasta\", file_format=\"fasta\")\n",
    "        else:\n",
    "            features_df = seq2features(entries, min_length=10, scaling=True)\n",
    "        return features_df\n",
    "    else:\n",
    "        features_list = []\n",
    "        for i in tqdm(range(0, len(entries), chunk_size), desc=\"Feature extraction\"):\n",
    "            chunk = entries[i : i + chunk_size]\n",
    "            features_chunk = seq2features(chunk, min_length=10, scaling=True)\n",
    "            features_list.append(features_chunk)\n",
    "        return pd.concat(features_list)\n",
    "\n",
    "\n",
    "def save_results(features_df, output_file):\n",
    "    features_df = features_df.reset_index().rename(columns={\"index\": \"id\"})\n",
    "    features_df = features_df.drop(columns=[\"md5\"])\n",
    "    features_df.to_parquet(output_file)\n",
    "    print(f\"Features saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sequences: 100%|██████████| 5095/5095 [00:00<00:00, 754536.36it/s]\n",
      "Feature extraction: 100%|██████████| 51/51 [00:06<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to ../dataset/demonstration_samples/Escherichia_coli_O157_H7_str_FRIK2000/features.pa\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load sequences\n",
    "    entries = load_sequences(\n",
    "        \"../dataset/demonstration_samples/Escherichia_coli_O157_H7_str_FRIK2000/protein.faa\"\n",
    "    )\n",
    "\n",
    "    # Generate features\n",
    "    features_df = generate_features(entries, chunk_size=100)\n",
    "\n",
    "    # Save results\n",
    "    save_results(\n",
    "        features_df,\n",
    "        \"../dataset/demonstration_samples/Escherichia_coli_O157_H7_str_FRIK2000/features.pa\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_parquet(\n",
    "    \"../dataset/demonstration_samples/Escherichia_coli_O157_H7_str_FRIK2000/features.pa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'PROSITE:ASX_HYDROXYL', 'PROSITE:PHOSPHOPANTETHEINE',\n",
      "       'PROSITE:EF_HAND_1', 'PROSITE:EGF_1', 'PROSITE:HOMEOBOX_1',\n",
      "       'PROSITE:ZINC_FINGER_C2H2_1', 'PROSITE:DEAD_ATP_HELICASE',\n",
      "       'PROSITE:RIBOSOMAL_S12', 'PROSITE:CYTOCHROME_P450',\n",
      "       ...\n",
      "       'RED_TRIPEP:SSA', 'RED_TRIPEP:SSC', 'RED_TRIPEP:SSE', 'RED_TRIPEP:SSF',\n",
      "       'RED_TRIPEP:SSG', 'RED_TRIPEP:SSH', 'RED_TRIPEP:SSK', 'RED_TRIPEP:SSL',\n",
      "       'RED_TRIPEP:SSP', 'RED_TRIPEP:SSS'],\n",
      "      dtype='object', length=1712)\n"
     ]
    }
   ],
   "source": [
    "print(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5095, 1712)\n",
      "5095\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(features[\"id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_ids = pd.read_csv(\"../dataset/pcat/all_unique_proteins.csv\")\n",
    "unique_ids = all_unique_ids[\"id\"]\n",
    "len(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only rows in features that have an id in unique_ids\n",
    "features = features[features[\"id\"].isin(unique_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)\n",
    "print(features[\"id\"].nunique())\n",
    "print(features[\"md5\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=[\"md5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features\n",
    "features.to_parquet(\"../dataset/protein_features_unique.pa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unique proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_features_unique = pd.read_parquet(\"../dataset/protein_features_unique.pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names and save to CSV\n",
    "column_names = pd.DataFrame(protein_features_unique.columns, columns=[\"feature_name\"])\n",
    "column_names.to_csv(\"../dataset/feature_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the feature columns where it contains \"DIPEP\" or \"TRIPEP\" in the name\n",
    "protein_features_unique = protein_features_unique.drop(\n",
    "    columns=[\n",
    "        col\n",
    "        for col in protein_features_unique.columns\n",
    "        if \"DIPEP\" in col or \"TRIPEP\" in col\n",
    "    ]\n",
    ")\n",
    "protein_features_unique.to_parquet(\n",
    "    \"../dataset/protein_features_unique_no_dipep_tripep.pa\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_features_unique.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
