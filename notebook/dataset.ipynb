{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata: genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_excel(\n",
    "    \"../dataset/AllSatellitesTables.xlsx\", sheet_name=\"PICI\", engine=\"openpyxl\"\n",
    ")\n",
    "print(df_0.shape)\n",
    "print(df_0.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"../dataset/PICI_GenomicNucInfo_060723.csv\")\n",
    "print(metadata.shape)\n",
    "print(metadata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"PICI_ID_allsets\"] = metadata[\"PICI_ID\"].str.split(\".Set\", n=1).str[0]\n",
    "cols = [\"PICI_ID_allsets\"] + [\n",
    "    col for col in metadata.columns if col != \"PICI_ID_allsets\"\n",
    "]\n",
    "metadata = metadata[cols]\n",
    "metadata = metadata.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_sets = metadata.groupby(\"PICI_ID_allsets\")[\"PICI_ID\"].nunique()\n",
    "duplicated_sets = duplicated_sets[duplicated_sets > 1].index\n",
    "duplicate_rows = metadata[metadata[\"PICI_ID_allsets\"].isin(duplicated_sets)]\n",
    "duplicate_rows = duplicate_rows.sort_values([\"PICI_ID_allsets\", \"PICI_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows.to_csv(\"../dataset/duplicate_picis.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(metadata[\"PICI_ID_allsets\"].unique()))\n",
    "print(len(metadata[\"PICI_ID\"].unique()))\n",
    "print(len(duplicate_rows[\"PICI_ID_allsets\"].unique()))\n",
    "print(len(duplicate_rows[\"PICI_ID\"].unique()))\n",
    "# 1435 - 1286 = 287 - 138 = 149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata: protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list(SeqIO.parse(\"../dataset/PICI_NucSequences_060723.fst\", \"fasta\"))\n",
    "print(len(seqs))\n",
    "print(\"first sample:\")\n",
    "print(seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_prt_1 = list(\n",
    "    SeqIO.parse(\n",
    "        \"../dataset/SatelliteProteomes/ACER001.0321.00001.C001.PICI.TypeB.variant0001.Set1.prt\",\n",
    "        \"fasta\",\n",
    "    )\n",
    ")\n",
    "print(len(seqs_prt_1))\n",
    "print(seqs_prt_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prt = []\n",
    "\n",
    "prt_files = glob.glob(\"../dataset/SatelliteProteomes/*.prt\")\n",
    "\n",
    "for prt_file in prt_files:\n",
    "    sequences = list(SeqIO.parse(prt_file, \"fasta\"))\n",
    "\n",
    "    for seq in sequences:\n",
    "        # Extract function (part after the last '|')\n",
    "        function = (\n",
    "            seq.description.split(\"|\")[-1].strip() if \"|\" in seq.description else \"\"\n",
    "        )\n",
    "\n",
    "        # Extract PICI_ID (everything before the last underscore in Protein_ID)\n",
    "        pici_id = \"_\".join(seq.id.split(\"_\")[:-1])\n",
    "\n",
    "        # Create dictionary for this entry\n",
    "        entry = {\n",
    "            \"PICI_ID\": pici_id,\n",
    "            \"Protein_ID\": seq.id,\n",
    "            \"Function\": function,\n",
    "            \"Description\": seq.description,\n",
    "        }\n",
    "\n",
    "        data_prt.append(entry)\n",
    "\n",
    "df_prt = pd.DataFrame(data_prt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prt[\"PICI_ID_allsets\"] = df_prt[\"PICI_ID\"].str.split(\".Set\", n=1).str[0]\n",
    "cols = [\"PICI_ID_allsets\"] + [col for col in df_prt.columns if col != \"PICI_ID_allsets\"]\n",
    "df_prt = df_prt[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prt.to_csv(\"../dataset/PICI_proteins.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prt = pd.read_csv(\"../dataset/PICI_proteins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_prt[\"PICI_ID_allsets\"].unique()))\n",
    "print(len(df_prt[\"PICI_ID\"].unique()))\n",
    "print(len(df_prt[\"Protein_ID\"].unique()))\n",
    "print(len(df_prt[\"Description\"].unique()))\n",
    "print(len(df_prt[\"Function\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### protein function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_counts = pd.read_csv(\"../results/proteins_all_function_counts.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function_counts = df_prt[\"Function\"].value_counts().reset_index(name=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrase_count = function_counts[function_counts[\"Function\"].str.contains(\"integrase\")]\n",
    "integrase_count.to_csv(\"../dataset/proteins_integrases.csv\", index=False)\n",
    "alpa_count = function_counts[function_counts[\"Function\"].str.contains(\"AlpA\")]\n",
    "alpa_count.to_csv(\"../dataset/proteins_AlpA.csv\", index=False)\n",
    "capsid_count = function_counts[function_counts[\"Function\"].str.contains(\"capsid\")]\n",
    "capsid_count.to_csv(\"../dataset/proteins_capsid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pici_functions = df_prt.groupby(\"PICI_ID\")[\"Function\"].agg(list)\n",
    "\n",
    "\n",
    "def check_functions(func_list):\n",
    "    func_str = \" \".join(func_list).lower()\n",
    "    return \"alpa\" in func_str\n",
    "\n",
    "\n",
    "# (\"integrase\" in func_str) and ('capsid' not in func_str)\n",
    "\n",
    "filtered_picis = pici_functions[pici_functions.apply(check_functions)]\n",
    "\n",
    "result_df = pd.DataFrame(\n",
    "    {\"PICI_ID\": filtered_picis.index, \"All_Functions\": filtered_picis.values}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"../results/picis_integrase_alpa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cfpici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prt = pd.read_csv(\"../dataset/PICI_proteins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_prt[\n",
    "#     df_prt[\"PICI_ID\"].str.contains(\"CFPICI\") & df_prt[\"Function\"].str.contains(\"capsid\")\n",
    "# ]\n",
    "len(df_prt[df_prt[\"PICI_ID\"].str.contains(\"CFPICI\")][\"PICI_ID\"].unique())\n",
    "# there are 30 cfpici among 1435 picis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list(SeqIO.parse(\"../dataset/PICI_NucSequences_060723.fst\", \"fasta\"))\n",
    "print(seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in seqs:\n",
    "    if seq.description == \"SIME002.0321.00024.C001.PICI.TypeB.variant0001.SetR1\":\n",
    "        print(seq)\n",
    "        print(len(seq.seq))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pici_30 = list(\n",
    "    [\n",
    "        \"SIME002.0321.00024.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"SIME002.0321.00009.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00005.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"LAPL001.0321.00074.C001.PICI.TypeB.variant0003.SetR1\",\n",
    "        \"SIME002.0321.00018.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00003.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"LAPL001.0321.00073.C001.PICI.TypeB.variant0003.SetR1\",\n",
    "        \"SIME002.0321.00002.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"STAU002.0321.00280.C001.PICI.TypeB.variant0004.SetR1\",\n",
    "        \"SPYA001.0321.00006.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"ESCO001.0321.00563.C001.PICI.TypeA.SetR1\",\n",
    "        \"ESCO001.0321.00097.C001.PICI.TypeA.SetR1\",\n",
    "        \"CIFR005.0321.00052.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00004.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"CIFR005.0321.00053.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"DEVU001.0321.00001.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"ESCO001.0321.00309.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"ESCO001.0321.01281.C001.PICI.TypeA.SetR1\",\n",
    "        \"DEVU001.0321.00001.C001.PICI.TypeB.variant0001.SetR2\",\n",
    "        \"PAKO001.0321.00001.C001.PICI.TypeB.variant0004.SetR1\",\n",
    "        \"DEVU001.0321.00004.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00006.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"ESCO001.0321.00448.C001.PICI.TypeA.SetR1\",\n",
    "        \"NIHA002.0321.00001.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"RHET001.0321.00004.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"CIFR005.0321.00101.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"STAR001.0321.00001.C001.PICI.TypeB.variant0002.SetR1\",\n",
    "        \"PAKO001.0321.00001.C002.PICI.TypeB.variant0004.SetR1\",\n",
    "        \"CIAM001.0321.00007.C001.PICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSA003.0321.00008.C001.PICI.TypeB.variant0002.SetR1\",\n",
    "    ]\n",
    ")\n",
    "cfpici_30 = list(\n",
    "    [\n",
    "        \"ESCO001.0321.01281.C001.CFPICI.TypeA.SetR1\",\n",
    "        \"CIFR005.0321.00053.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSA003.0321.00008.C001.CFPICI.TypeB.variant0002.SetR1\",\n",
    "        \"DEVU001.0321.00001.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"CIFR005.0321.00052.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"DEVU001.0321.00004.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00003.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00004.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"LAPL001.0321.00074.C001.CFPICI.TypeB.variant0003.SetR1\",\n",
    "        \"ESCO001.0321.00097.C001.CFPICI.TypeA.SetR1\",\n",
    "        \"DEVU001.0321.00001.C001.CFPICI.TypeB.variant0001.SetR2\",\n",
    "        \"SPYA001.0321.00006.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00005.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"RHET001.0321.00004.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"ESCO001.0321.00309.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"SIME002.0321.00002.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"PAKO001.0321.00001.C002.CFPICI.TypeB.variant0004.SetR1\",\n",
    "        \"STAU002.0321.00280.C001.CFPICI.TypeB.variant0004.SetR1\",\n",
    "        \"SIME002.0321.00009.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"STSI001.0321.00006.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"CIFR005.0321.00101.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"LAPL001.0321.00073.C001.CFPICI.TypeB.variant0003.SetR1\",\n",
    "        \"SIME002.0321.00024.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"ESCO001.0321.00563.C001.CFPICI.TypeA.SetR1\",\n",
    "        \"STAR001.0321.00001.C001.CFPICI.TypeB.variant0002.SetR1\",\n",
    "        \"ESCO001.0321.00448.C001.CFPICI.TypeA.SetR1\",\n",
    "        \"CIAM001.0321.00007.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"PAKO001.0321.00001.C001.CFPICI.TypeB.variant0004.SetR1\",\n",
    "        \"NIHA002.0321.00001.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "        \"SIME002.0321.00018.C001.CFPICI.TypeB.variant0001.SetR1\",\n",
    "    ]\n",
    ")\n",
    "print(len(pici_30), len(cfpici_30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only 1405 picis from seqs excluding 30 cfpici\n",
    "seqs = [seq for seq in seqs if seq.id not in cfpici_30]\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1405\n",
    "# write to fasta\n",
    "with open(\"../dataset/PICI_NucSequences_060723_no_cfpici.fst\", \"w\") as f:\n",
    "    for seq in seqs:\n",
    "        f.write(f\">{seq.id}\\n{seq.seq}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prt = pd.read_csv(\"../dataset/PICI_proteins.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_matrix = pd.pivot_table(\n",
    "    df_prt,\n",
    "    values=\"Protein_ID\",\n",
    "    index=\"PICI_ID\",\n",
    "    columns=\"Function\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_matrix.to_csv(\"../results/protein_function_matrix_old.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(function_matrix.sum().sum())  # should be same as df_prt.shape[0]\n",
    "print(function_matrix.max().max())\n",
    "print(function_matrix.min().min())\n",
    "print(function_matrix.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_mask = function_matrix.columns.str.contains(\"integrase|alpa|capsid\", case=False)\n",
    "col_mask = function_matrix.columns.str.contains(\"alpa\", case=False)\n",
    "function_matrix_integrase_alpa_capsid = function_matrix.loc[:, col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_matrix_integrase_alpa_capsid.to_csv(\n",
    "    \"../results/protein_function_matrix_integrase_alpa_capsid.csv\", index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### new matrix with pharokka annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_function_matrix_old = pd.read_csv(\n",
    "    \"../results/protein_function_matrix_old.csv\", index_col=0\n",
    ")\n",
    "print(protein_function_matrix_old.shape)\n",
    "print(protein_function_matrix_old.info())\n",
    "print(protein_function_matrix_old.max().max())\n",
    "print(protein_function_matrix_old.min().min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phanotate_functions = pd.read_csv(\n",
    "    \"../results/pharokka_output/phanotate_functions.tsv\", sep=\"\\t\"\n",
    ")\n",
    "print(phanotate_functions.shape)\n",
    "print(phanotate_functions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_matrix_new_unmerged = pd.pivot_table(\n",
    "    phanotate_functions,\n",
    "    values=\"gene_id\",\n",
    "    index=\"pici_id\",\n",
    "    columns=\"function\",\n",
    "    aggfunc=\"count\",\n",
    "    fill_value=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(function_matrix_new_unmerged.shape)\n",
    "print(function_matrix_new_unmerged.info())\n",
    "print(function_matrix_new_unmerged.max().max())\n",
    "print(function_matrix_new_unmerged.min().min())\n",
    "function_matrix_new_unmerged.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_matrix_new_unmerged.to_csv(\n",
    "    \"../results/protein_function_matrix_new_unmerged.csv\", index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_matrix_new_unmerged = pd.read_csv(\n",
    "    \"../results/protein_function_matrix_new_unmerged.csv\", index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpa_columns = [\n",
    "    \"AlpA family phage regulatory protein  (translation)\",\n",
    "    \"AlpA family transcriptional regulator  (translation)\",\n",
    "]\n",
    "\n",
    "function_matrix_new = function_matrix_new_unmerged.drop(index=pici_30)\n",
    "alpa_data = function_matrix[alpa_columns].drop(index=cfpici_30)\n",
    "\n",
    "print(\"Shape after removal:\")\n",
    "print(\"function_matrix_new:\", function_matrix_new.shape)\n",
    "print(\"alpa_data:\", alpa_data.shape)\n",
    "\n",
    "print(\"\\nIndices identical:\", (function_matrix_new.index == alpa_data.index).all())\n",
    "\n",
    "function_matrix_new = pd.concat([function_matrix_new, alpa_data], axis=1).fillna(0)\n",
    "\n",
    "print(\"\\nFinal shape:\", function_matrix_new.shape)\n",
    "print(\"Number of unique indices:\", len(function_matrix_new.index.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_matrix_new.to_csv(\n",
    "    \"../results/protein_function_matrix_new_merged.csv\", index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(function_matrix_new.shape)\n",
    "print(function_matrix_new.info())\n",
    "print(function_matrix_new.max().max())\n",
    "print(function_matrix_new.min().min())\n",
    "function_matrix_new.sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "\n",
    "# Create directory for split files\n",
    "os.makedirs(\"../dataset/split_sequences\", exist_ok=True)\n",
    "\n",
    "# Split each sequence into its own file\n",
    "count = 0\n",
    "for record in SeqIO.parse(\"../dataset/PICI_NucSequences_060723.fst\", \"fasta\"):\n",
    "    count += 1\n",
    "    # Use the sequence ID as filename, replacing any problematic characters\n",
    "    safe_filename = record.id.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    output_file = f\"../dataset/split_sequences/{safe_filename}.fasta\"\n",
    "    with open(output_file, \"w\") as output_handle:\n",
    "        SeqIO.write(record, output_handle, \"fasta\")\n",
    "\n",
    "print(f\"Split {count} sequences into individual files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mash_dist = pd.read_csv(\"../output/mash_distances.tab\", sep=\"\\t\")\n",
    "print(mash_dist.shape)\n",
    "print(mash_dist.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column names\n",
    "mash_dist.columns = [\"seq1\", \"seq2\", \"distance\", \"pvalue\", \"matching_hashes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mash_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(mash_dist[\"distance\"], bins=1000)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# phage_satellites_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = pd.read_parquet(\"../dataset/Phage_and_Satellites_Pann_Pcat_Pcol.pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotation[\"acc\"].nunique())\n",
    "print(annotation[\"name\"].nunique())\n",
    "print(annotation[\"strand\"].nunique())\n",
    "print(annotation[\"pann\"].nunique())\n",
    "print(annotation[\"pcat\"].nunique())\n",
    "print(annotation[\"pcol\"].nunique())\n",
    "print(annotation[\"translation\"].nunique())\n",
    "print(annotation[\"what\"].nunique())\n",
    "print(annotation[\"translation\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation[annotation[\"pcat\"] == \"moron, auxiliary metabolic gene and host takeover\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotation[\"pcat\"].unique())\n",
    "print(annotation[\"pcol\"].unique())\n",
    "print(annotation[\"what\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation[\"pcat\"].value_counts()\n",
    "# leave out: unknown_no_hit\n",
    "# start with tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out where pcat is unknown_no_hit\n",
    "annotation = annotation[annotation[\"pcat\"] != \"unknown_no_hit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(annotation.shape)\n",
    "print(annotation[\"translation\"].nunique())\n",
    "print(annotation[\"pcat\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_translations = annotation[annotation.duplicated(\"translation\", keep=False)]\n",
    "for seq, group in duplicated_translations.groupby(\"translation\"):\n",
    "    print(f\"Protein sequence: {seq[:30]}...\")  # Print first 30 chars for brevity\n",
    "    print(group[[\"name\"]])\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_seq = annotation.loc[\n",
    "#     annotation[\"name\"] == \"EZLKZNME_CDS_0010\", \"translation\"\n",
    "# ].iloc[0]\n",
    "# same_seq_rows = annotation[annotation[\"translation\"] == target_seq]\n",
    "# same_seq_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcat_counts = annotation.groupby(\"translation\")[\"pcat\"].nunique()\n",
    "multi_pcat_seqs = pcat_counts[pcat_counts > 1].index\n",
    "rows_with_multi_pcat = annotation[annotation[\"translation\"].isin(multi_pcat_seqs)]\n",
    "rows_with_multi_pcat\n",
    "# conclusion: the ones with same translation must have same pcat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"pcat\":function, file name\n",
    "\"name\": id\n",
    "\"pann\": description\n",
    "\"translation\": sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ensure output directory exists (optional)\n",
    "output_dir = \"../dataset/fasta_by_pcat\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for pcat_value in annotation[\"pcat\"].unique():\n",
    "    # Format the filename: lowercase, replace spaces/commas with underscores, remove other non-alphanumerics\n",
    "    filename = pcat_value.lower().replace(\",\", \"\").replace(\" \", \"_\") + \".fa\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Select rows for this pcat\n",
    "    subset = annotation[annotation[\"pcat\"] == pcat_value]\n",
    "\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for _, row in subset.iterrows():\n",
    "            # Prepare header and sequence\n",
    "            header = (\n",
    "                f\">{row['name']} {row['pann']}\"\n",
    "                if pd.notna(row[\"pann\"])\n",
    "                else f\">{row['name']}\"\n",
    "            )\n",
    "            sequence = row[\"translation\"]\n",
    "            # Write to file\n",
    "            f.write(f\"{header}\\n{sequence}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "seen_sequences = set()\n",
    "unique_records = []\n",
    "\n",
    "for record in SeqIO.parse(\"../dataset/combined_proteins.fa\", \"fasta\"):\n",
    "    if str(record.seq) not in seen_sequences:\n",
    "        seen_sequences.add(str(record.seq))\n",
    "        unique_records.append(record)\n",
    "\n",
    "SeqIO.write(unique_records, \"../dataset/unique_proteins.fa\", \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation[\"pcat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the names for each pcat\n",
    "for pcat, group in annotation.groupby(\"pcat\"):\n",
    "    group[\"name\"].to_csv(f\"../dataset/pcat/{pcat}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_proteins = list(SeqIO.parse(\"../dataset/unique_proteins.fa\", \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_proteins[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the ids of unique proteins to csv\n",
    "list_of_ids = []\n",
    "for protein in unique_proteins:\n",
    "    list_of_ids.append(protein.id)\n",
    "pd.DataFrame(list_of_ids, columns=[\"id\"]).to_csv(\n",
    "    \"../dataset/pcat/all_unique_proteins.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statistics\n",
    "\n",
    "# Load the cluster mapping\n",
    "with open(\"../dataset/protein_cluster_mapping.json\", \"r\") as f:\n",
    "    protein_to_cluster = json.load(f)\n",
    "\n",
    "# Count the number of proteins in each cluster\n",
    "from collections import Counter\n",
    "\n",
    "sizes = Counter(protein_to_cluster.values()).values()\n",
    "sizes = list(sizes)\n",
    "\n",
    "# Print statistics using the statistics module\n",
    "print(f\"Total number of clusters: {len(sizes)}\")\n",
    "print(f\"Smallest cluster: {min(sizes)}\")\n",
    "print(f\"Largest cluster: {max(sizes)}\")\n",
    "print(f\"Average cluster size: {statistics.mean(sizes):.2f}\")\n",
    "print(f\"Median cluster size: {statistics.median(sizes)}\")\n",
    "if len(sizes) > 1:\n",
    "    print(f\"Standard deviation: {statistics.stdev(sizes):.2f}\")\n",
    "else:\n",
    "    print(\"Standard deviation: N/A (only one cluster)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cluster_sizes = Counter(protein_to_cluster.values())\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"cluster_number\": list(cluster_sizes.keys()),\n",
    "        \"cluster_size\": list(cluster_sizes.values()),\n",
    "    }\n",
    ")\n",
    "df = df.sort_values(\"cluster_size\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../results/cluster_sizes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(sizes, bins=1000)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bacteria for demonstration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frik_bacteria_proteins = list(\n",
    "    SeqIO.parse(\n",
    "        \"../dataset/demonstration_samples/Escherichia_coli_O157_H7_str_FRIK2000/protein.faa\",\n",
    "        \"fasta\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(frik_bacteria_proteins))\n",
    "print(frik_bacteria_proteins[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_gff(gff_file):\n",
    "    records = []\n",
    "    with open(gff_file) as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) < 9 or parts[2] != \"CDS\":\n",
    "                continue\n",
    "            contig = parts[0]\n",
    "            start = int(parts[3])\n",
    "            end = int(parts[4])\n",
    "            strand = parts[6]\n",
    "            attributes = parts[8]\n",
    "            # Try to extract protein_id or ID\n",
    "            protein_id = None\n",
    "            for attr in attributes.split(\";\"):\n",
    "                if attr.startswith(\"protein_id=\"):\n",
    "                    protein_id = attr.split(\"=\")[1]\n",
    "                    break\n",
    "                elif attr.startswith(\"ID=\"):\n",
    "                    protein_id = attr.split(\"=\")[1]\n",
    "            if protein_id:\n",
    "                records.append(\n",
    "                    {\n",
    "                        \"protein_id\": protein_id,\n",
    "                        \"contig\": contig,\n",
    "                        \"start\": start,\n",
    "                        \"end\": end,\n",
    "                        \"strand\": strand,\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_df = parse_gff(\n",
    "    \"../dataset/demonstration_samples/Escherichia_coli_O157_H7_str_FRIK2000/genomic.gff\"\n",
    ")\n",
    "gff_df = gff_df.sort_values([\"contig\", \"start\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_df[\"contig\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((gff_df[\"protein_id\"] == sorted(gff_df[\"protein_id\"])).all())\n",
    "print((gff_df[\"start\"] == sorted(gff_df[\"start\"])).all())\n",
    "print((gff_df[\"end\"] == sorted(gff_df[\"end\"])).all())\n",
    "print((gff_df[\"contig\"] == sorted(gff_df[\"contig\"])).all())\n",
    "print(gff_df.equals(gff_df.sort_values([\"contig\", \"start\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff_df.to_csv(\n",
    "    \"../dataset/demonstration_samples/Escherichia_coli_O157_H7_str_FRIK2000/gff_df.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# known segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = pd.read_parquet(\"../dataset/Phage_and_Satellites_Pann_Pcat_Pcol.pa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see each of what's length\n",
    "# annotation_pici = annotation[annotation[\"what\"] == \"PICI\"]\n",
    "# annotation_cfpici = annotation[annotation[\"what\"] == \"CFPICI\"]\n",
    "# annotation_p4 = annotation[annotation[\"what\"] == \"P4\"]\n",
    "# annotation_phage = annotation[annotation[\"what\"] == \"phage\"]\n",
    "\n",
    "# see the average length of each acc in each what\n",
    "# annotation_phage[\"acc\"].value_counts().mean()\n",
    "# print(f\"phage: {annotation_phage['acc'].value_counts().describe()}\")\n",
    "# print(f\"pici: {annotation_pici['acc'].value_counts().describe()}\")\n",
    "# print(f\"cfpici: {annotation_cfpici['acc'].value_counts().describe()}\")\n",
    "# print(f\"p4: {annotation_p4['acc'].value_counts().describe()}\")\n",
    "\n",
    "# conclusion: satellites have max length of 44\n",
    "\n",
    "phage_gene_counts = (\n",
    "    annotation[annotation[\"what\"] == \"phage\"]\n",
    "    .groupby(\"acc\")[\"name\"]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    ")\n",
    "phage_gene_counts.columns = [\"acc\", \"gene_num\"]\n",
    "\n",
    "phage_small = phage_gene_counts[\n",
    "    (phage_gene_counts[\"gene_num\"] >= 10) & (phage_gene_counts[\"gene_num\"] <= 50)\n",
    "]\n",
    "phage_small_200 = phage_small.sample(n=200, random_state=42)\n",
    "annotation_phage_small_200 = annotation[annotation[\"acc\"].isin(phage_small_200[\"acc\"])]\n",
    "annotation_phage_small_200.to_csv(\n",
    "    \"../dataset/demonstration_samples/known_segments/annotation_phage_small_200.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotation = pd.read_parquet(\"../dataset/Phage_and_Satellites_Pann_Pcat_Pcol.pa\")\n",
    "\n",
    "# # id 200 random samples for each type\n",
    "# pici_acc_200 = list(\n",
    "#     np.random.choice(\n",
    "#         annotation[annotation[\"what\"] == \"PICI\"][\"acc\"].unique(), 200, replace=False\n",
    "#     )\n",
    "# )\n",
    "# cf_acc_200 = list(\n",
    "#     np.random.choice(\n",
    "#         annotation[annotation[\"what\"] == \"CFPICI\"][\"acc\"].unique(), 200, replace=False\n",
    "#     )\n",
    "# )\n",
    "# p4_acc_200 = list(\n",
    "#     np.random.choice(\n",
    "#         annotation[annotation[\"what\"] == \"P4\"][\"acc\"].unique(), 200, replace=False\n",
    "#     )\n",
    "# )\n",
    "# phage_acc_200 = list(\n",
    "#     np.random.choice(\n",
    "#         annotation[annotation[\"what\"] == \"phage\"][\"acc\"].unique(), 200, replace=False\n",
    "#     )\n",
    "# )\n",
    "# all_acc_200 = pici_acc_200 + cf_acc_200 + p4_acc_200 + phage_acc_200\n",
    "\n",
    "# # merge all the samples\n",
    "# samples = annotation[annotation[\"acc\"].isin(all_acc_200)]\n",
    "# print(samples[\"acc\"].nunique())\n",
    "\n",
    "# samples.to_csv(\n",
    "#     \"../dataset/demonstration_samples/known_segments/annotation_200.csv\", index=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6829\n",
      "200\n",
      "(6829, 10)\n"
     ]
    }
   ],
   "source": [
    "samples = pd.read_csv(\n",
    "    \"../dataset/demonstration_samples/known_segments/annotation_phage_small_200.csv\"\n",
    ")\n",
    "samples_acc = samples[\"acc\"].unique()\n",
    "samples_protein_id = samples[\"name\"].unique()\n",
    "\n",
    "print(len(samples_protein_id))\n",
    "print(len(samples_acc))\n",
    "print(samples.shape)\n",
    "\n",
    "with open(\n",
    "    \"../dataset/demonstration_samples/known_segments/proteins_phage_small_200.faa\", \"w\"\n",
    ") as f:\n",
    "    for idx, row in samples.iterrows():\n",
    "        f.write(f\">{row['name']}\\n\")\n",
    "        f.write(f\"{row['translation']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
